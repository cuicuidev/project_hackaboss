{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for i, device in enumerate(physical_devices):\n",
    "    print(f\"GPU {i}: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'car_make_images/'\n",
    "training_path = path + 'train'\n",
    "testing_path = path + 'test'\n",
    "validation_path = path + 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_generator = ImageDataGenerator(rescale = 1./255,\n",
    "                              rotation_range = 359,\n",
    "                              shear_range = 0.2,\n",
    "                              width_shift_range = 0.2,\n",
    "                              height_shift_range = 0.2,\n",
    "                              zoom_range = 0.2,\n",
    "                              horizontal_flip = True,\n",
    "                              vertical_flip = True,\n",
    "                              preprocessing_function = None)\n",
    "\n",
    "validation_data_generator = ImageDataGenerator(rescale = 1./255)\n",
    "test_data_generator = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11573 images belonging to 39 classes.\n",
      "Found 2813 images belonging to 39 classes.\n",
      "Found 2871 images belonging to 39 classes.\n"
     ]
    }
   ],
   "source": [
    "size = 512\n",
    "batch_size = 32  \n",
    "num_classes = 39\n",
    "\n",
    "training_generator = training_data_generator.flow_from_directory(training_path,\n",
    "                                                                 target_size = (size, size),\n",
    "                                                                 batch_size = 30,\n",
    "                                                                 class_mode = \"categorical\",\n",
    "                                                                 color_mode = 'grayscale',\n",
    "                                                                 )\n",
    "\n",
    "validation_generator = validation_data_generator.flow_from_directory(validation_path,\n",
    "                                                                     target_size = (size, size),\n",
    "                                                                     batch_size = 1,\n",
    "                                                                     class_mode = \"categorical\",\n",
    "                                                                     color_mode = 'grayscale',\n",
    "                                                                     )\n",
    "\n",
    "test_generator = test_data_generator.flow_from_directory(testing_path,\n",
    "                                                         target_size = (size, size),\n",
    "                                                         batch_size = 1,\n",
    "                                                         class_mode = \"categorical\",\n",
    "                                                         color_mode = 'grayscale',\n",
    "                                                         shuffle=False\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(size, size, 1)))\n",
    "\n",
    "# First Conv Block\n",
    "model.add(Conv2D(filters=16, kernel_size=7, padding='same', kernel_initializer='he_normal'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Second Conv Block\n",
    "model.add(Conv2D(filters=32, kernel_size=5, padding='same', kernel_initializer='he_normal'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Third Conv Block\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Flatten and Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(num_classes, activation='softmax', kernel_initializer='he_normal'))\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=0.001,\n",
    "            decay_steps=10000,\n",
    "            decay_rate=0.9)\n",
    "opt = Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(model, train_data, val_data, epochs, save_interval, model_save_path, history_save_path, custom_metrics=None, custom_optimizer=None):\n",
    "    \"\"\"\n",
    "    Train a TensorFlow model and save it along with its history.\n",
    "    \"\"\"\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "    if custom_optimizer:\n",
    "        optimizer = custom_optimizer\n",
    "    else:\n",
    "        optimizer = 'adam'\n",
    "\n",
    "    if custom_metrics:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'] + custom_metrics)\n",
    "    else:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    # Initialize variables\n",
    "    initial_epoch = 0\n",
    "    temp_history_data = []\n",
    "\n",
    "    # Check if history file exists, if not create it\n",
    "    if not os.path.exists(history_save_path):\n",
    "        with open(history_save_path, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            columns = ['Epoch', 'Loss', 'Accuracy', 'Val_Loss', 'Val_Accuracy']\n",
    "            if custom_metrics:\n",
    "                for metric in custom_metrics:\n",
    "                    metric_name = metric.__name__\n",
    "                    columns.append(metric_name)\n",
    "                    columns.append(\"Val_\" + metric_name)\n",
    "            csv_writer.writerow(columns)\n",
    "    else:\n",
    "        with open(history_save_path, 'r') as csvfile:\n",
    "            csv_reader = csv.reader(csvfile)\n",
    "            last_row = None\n",
    "            for row in csv_reader:\n",
    "                last_row = row\n",
    "            if last_row:\n",
    "                initial_epoch = int(last_row[0])\n",
    "\n",
    "    latest_model_file = max(glob.glob(f\"{model_save_path}/model_e*.h5\"), default=None, key=os.path.getctime)\n",
    "    if latest_model_file is not None:\n",
    "        print(f\"Resuming from {latest_model_file}\")\n",
    "        model = tf.keras.models.load_model(latest_model_file, custom_objects={metric.__name__: metric for metric in custom_metrics})\n",
    "\n",
    "    for epoch in range(initial_epoch + 1, epochs + initial_epoch + 1):\n",
    "        print(f\"Epoch {epoch}/{epochs + initial_epoch}\")\n",
    "\n",
    "        history = model.fit(train_data, validation_data=val_data)\n",
    "        history_data = [epoch] + [history.history[key][0] for key in history.history]\n",
    "        temp_history_data.append(history_data)\n",
    "\n",
    "        if epoch % save_interval == 0 or epoch == epochs + initial_epoch:\n",
    "            model_file_path = os.path.join(model_save_path, f\"model_e{epoch}.h5\")\n",
    "            model.save(model_file_path)\n",
    "\n",
    "            # Append to CSV at checkpoints\n",
    "            with open(history_save_path, 'a', newline='') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                for row in temp_history_data:\n",
    "                    csv_writer.writerow(row)\n",
    "\n",
    "            # Clear temporary history data\n",
    "            temp_history_data.clear()\n",
    "\n",
    "            print(f\"Saved model and history at epoch {epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "386/386 [==============================] - 485s 1s/step - loss: 4.2745 - accuracy: 0.0366 - val_loss: 3.6248 - val_accuracy: 0.0430\n",
      "Epoch 2/100\n",
      "386/386 [==============================] - 330s 854ms/step - loss: 3.6278 - accuracy: 0.0419 - val_loss: 3.6192 - val_accuracy: 0.0459\n",
      "Epoch 3/100\n",
      "386/386 [==============================] - 331s 857ms/step - loss: 3.6195 - accuracy: 0.0445 - val_loss: 3.6105 - val_accuracy: 0.0483\n",
      "Epoch 4/100\n",
      "386/386 [==============================] - 331s 857ms/step - loss: 3.6099 - accuracy: 0.0449 - val_loss: 3.6130 - val_accuracy: 0.0501\n",
      "Epoch 5/100\n",
      "386/386 [==============================] - 336s 870ms/step - loss: 3.6028 - accuracy: 0.0479 - val_loss: 3.5938 - val_accuracy: 0.0526\n",
      "Epoch 6/100\n",
      "386/386 [==============================] - 333s 863ms/step - loss: 3.5962 - accuracy: 0.0526 - val_loss: 3.5865 - val_accuracy: 0.0540\n",
      "Epoch 7/100\n",
      "386/386 [==============================] - 334s 864ms/step - loss: 3.5884 - accuracy: 0.0518 - val_loss: 3.5779 - val_accuracy: 0.0540\n",
      "Epoch 8/100\n",
      " 72/386 [====>.........................] - ETA: 4:10 - loss: 3.5883 - accuracy: 0.0611"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cuicuidev\\Desktop\\project_hackaboss\\training.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the model and save it\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_and_save(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     training_generator, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     validation_generator, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     save_interval\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     model_save_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodels\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     history_save_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhistory.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     custom_metrics\u001b[39m=\u001b[39;49m[],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     custom_optimizer\u001b[39m=\u001b[39;49mopt\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\cuicuidev\\Desktop\\project_hackaboss\\training.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(initial_epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m initial_epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39minitial_epoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_data, validation_data\u001b[39m=\u001b[39;49mval_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     history_data \u001b[39m=\u001b[39m [epoch] \u001b[39m+\u001b[39m [history\u001b[39m.\u001b[39mhistory[key][\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m history\u001b[39m.\u001b[39mhistory]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cuicuidev/Desktop/project_hackaboss/training.ipynb#X10sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     temp_history_data\u001b[39m.\u001b[39mappend(history_data)\n",
      "File \u001b[1;32mc:\\Users\\cuicuidev\\Desktop\\project_hackaboss\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\cuicuidev\\Desktop\\project_hackaboss\\.env\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\cuicuidev\\Desktop\\project_hackaboss\\.env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\cuicuidev\\Desktop\\project_hackaboss\\.env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\cuicuidev\\Desktop\\project_hackaboss\\.env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\cuicuidev\\Desktop\\project_hackaboss\\.env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\cuicuidev\\Desktop\\project_hackaboss\\.env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\cuicuidev\\Desktop\\project_hackaboss\\.env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\cuicuidev\\Desktop\\project_hackaboss\\.env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model and save it\n",
    "\n",
    "train_and_save(\n",
    "    model, \n",
    "    training_generator, \n",
    "    validation_generator, \n",
    "    epochs=100, \n",
    "    save_interval=10, \n",
    "    model_save_path=\"models\", \n",
    "    history_save_path=\"history.csv\", \n",
    "    custom_metrics=[],\n",
    "    custom_optimizer=opt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from models\\model_e500.h5\n",
      "Epoch 501/650\n",
      "386/386 [==============================] - 273s 704ms/step - loss: 1.2068 - accuracy: 0.6456 - val_loss: 4.3441 - val_accuracy: 0.3249\n",
      "Epoch 502/650\n",
      "386/386 [==============================] - 158s 410ms/step - loss: 1.2154 - accuracy: 0.6467 - val_loss: 4.3033 - val_accuracy: 0.3374\n",
      "Epoch 503/650\n",
      "386/386 [==============================] - 160s 413ms/step - loss: 1.2074 - accuracy: 0.6449 - val_loss: 4.2728 - val_accuracy: 0.3324\n",
      "Epoch 504/650\n",
      "386/386 [==============================] - 172s 445ms/step - loss: 1.1901 - accuracy: 0.6542 - val_loss: 4.6231 - val_accuracy: 0.3146\n",
      "Epoch 505/650\n",
      "386/386 [==============================] - 171s 441ms/step - loss: 1.1991 - accuracy: 0.6529 - val_loss: 4.7306 - val_accuracy: 0.3171\n",
      "Epoch 506/650\n",
      "386/386 [==============================] - 179s 465ms/step - loss: 1.1803 - accuracy: 0.6522 - val_loss: 4.3119 - val_accuracy: 0.3370\n",
      "Epoch 507/650\n",
      "386/386 [==============================] - 180s 466ms/step - loss: 1.2180 - accuracy: 0.6361 - val_loss: 4.6244 - val_accuracy: 0.3235\n",
      "Epoch 508/650\n",
      "386/386 [==============================] - 178s 460ms/step - loss: 1.2071 - accuracy: 0.6410 - val_loss: 4.4557 - val_accuracy: 0.3306\n",
      "Epoch 509/650\n",
      "386/386 [==============================] - 176s 456ms/step - loss: 1.1936 - accuracy: 0.6501 - val_loss: 4.2657 - val_accuracy: 0.3391\n",
      "Epoch 510/650\n",
      "386/386 [==============================] - 170s 440ms/step - loss: 1.2000 - accuracy: 0.6484 - val_loss: 4.2104 - val_accuracy: 0.3391\n",
      "Saved model and history at epoch 510\n",
      "Epoch 511/650\n",
      "386/386 [==============================] - 172s 445ms/step - loss: 1.1888 - accuracy: 0.6475 - val_loss: 4.4332 - val_accuracy: 0.3317\n",
      "Epoch 512/650\n",
      "386/386 [==============================] - 168s 435ms/step - loss: 1.2021 - accuracy: 0.6474 - val_loss: 4.2915 - val_accuracy: 0.3324\n",
      "Epoch 513/650\n",
      "386/386 [==============================] - 169s 437ms/step - loss: 1.2015 - accuracy: 0.6478 - val_loss: 4.3715 - val_accuracy: 0.3359\n",
      "Epoch 514/650\n",
      "386/386 [==============================] - 171s 442ms/step - loss: 1.1730 - accuracy: 0.6529 - val_loss: 4.5567 - val_accuracy: 0.3352\n",
      "Epoch 515/650\n",
      "386/386 [==============================] - 170s 440ms/step - loss: 1.1740 - accuracy: 0.6566 - val_loss: 4.2750 - val_accuracy: 0.3409\n",
      "Epoch 516/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.2069 - accuracy: 0.6442 - val_loss: 4.3992 - val_accuracy: 0.3391\n",
      "Epoch 517/650\n",
      "386/386 [==============================] - 164s 426ms/step - loss: 1.1768 - accuracy: 0.6516 - val_loss: 4.3954 - val_accuracy: 0.3402\n",
      "Epoch 518/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1951 - accuracy: 0.6519 - val_loss: 4.4166 - val_accuracy: 0.3338\n",
      "Epoch 519/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1874 - accuracy: 0.6515 - val_loss: 4.3861 - val_accuracy: 0.3367\n",
      "Epoch 520/650\n",
      "386/386 [==============================] - 165s 426ms/step - loss: 1.1807 - accuracy: 0.6546 - val_loss: 4.7581 - val_accuracy: 0.3150\n",
      "Saved model and history at epoch 520\n",
      "Epoch 521/650\n",
      "386/386 [==============================] - 162s 418ms/step - loss: 1.2015 - accuracy: 0.6474 - val_loss: 4.3485 - val_accuracy: 0.3324\n",
      "Epoch 522/650\n",
      "386/386 [==============================] - 163s 423ms/step - loss: 1.1858 - accuracy: 0.6520 - val_loss: 4.4640 - val_accuracy: 0.3285\n",
      "Epoch 523/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1774 - accuracy: 0.6546 - val_loss: 4.3113 - val_accuracy: 0.3416\n",
      "Epoch 524/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1718 - accuracy: 0.6575 - val_loss: 4.3587 - val_accuracy: 0.3391\n",
      "Epoch 525/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1893 - accuracy: 0.6491 - val_loss: 4.3655 - val_accuracy: 0.3391\n",
      "Epoch 526/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1728 - accuracy: 0.6559 - val_loss: 4.4473 - val_accuracy: 0.3285\n",
      "Epoch 527/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1722 - accuracy: 0.6602 - val_loss: 4.4712 - val_accuracy: 0.3331\n",
      "Epoch 528/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1793 - accuracy: 0.6513 - val_loss: 4.4014 - val_accuracy: 0.3374\n",
      "Epoch 529/650\n",
      "386/386 [==============================] - 166s 428ms/step - loss: 1.1842 - accuracy: 0.6500 - val_loss: 4.4622 - val_accuracy: 0.3306\n",
      "Epoch 530/650\n",
      "386/386 [==============================] - 166s 429ms/step - loss: 1.1941 - accuracy: 0.6500 - val_loss: 4.3414 - val_accuracy: 0.3409\n",
      "Saved model and history at epoch 530\n",
      "Epoch 531/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1738 - accuracy: 0.6543 - val_loss: 4.3624 - val_accuracy: 0.3299\n",
      "Epoch 532/650\n",
      "386/386 [==============================] - 166s 428ms/step - loss: 1.1851 - accuracy: 0.6549 - val_loss: 4.3861 - val_accuracy: 0.3335\n",
      "Epoch 533/650\n",
      "386/386 [==============================] - 166s 429ms/step - loss: 1.1595 - accuracy: 0.6615 - val_loss: 4.2473 - val_accuracy: 0.3377\n",
      "Epoch 534/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1590 - accuracy: 0.6571 - val_loss: 4.3822 - val_accuracy: 0.3399\n",
      "Epoch 535/650\n",
      "386/386 [==============================] - 166s 429ms/step - loss: 1.1713 - accuracy: 0.6564 - val_loss: 4.3460 - val_accuracy: 0.3388\n",
      "Epoch 536/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1735 - accuracy: 0.6547 - val_loss: 4.3819 - val_accuracy: 0.3331\n",
      "Epoch 537/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1539 - accuracy: 0.6617 - val_loss: 4.3787 - val_accuracy: 0.3363\n",
      "Epoch 538/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1555 - accuracy: 0.6556 - val_loss: 4.5307 - val_accuracy: 0.3228\n",
      "Epoch 539/650\n",
      "386/386 [==============================] - 164s 426ms/step - loss: 1.1574 - accuracy: 0.6566 - val_loss: 4.5391 - val_accuracy: 0.3310\n",
      "Epoch 540/650\n",
      "386/386 [==============================] - 164s 425ms/step - loss: 1.1693 - accuracy: 0.6557 - val_loss: 4.4659 - val_accuracy: 0.3288\n",
      "Saved model and history at epoch 540\n",
      "Epoch 541/650\n",
      "386/386 [==============================] - 164s 426ms/step - loss: 1.1548 - accuracy: 0.6611 - val_loss: 4.5506 - val_accuracy: 0.3306\n",
      "Epoch 542/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1487 - accuracy: 0.6558 - val_loss: 4.3608 - val_accuracy: 0.3406\n",
      "Epoch 543/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1543 - accuracy: 0.6626 - val_loss: 4.4545 - val_accuracy: 0.3320\n",
      "Epoch 544/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1412 - accuracy: 0.6640 - val_loss: 4.4118 - val_accuracy: 0.3352\n",
      "Epoch 545/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1414 - accuracy: 0.6649 - val_loss: 4.2741 - val_accuracy: 0.3512\n",
      "Epoch 546/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1337 - accuracy: 0.6703 - val_loss: 4.3976 - val_accuracy: 0.3413\n",
      "Epoch 547/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1555 - accuracy: 0.6589 - val_loss: 4.4841 - val_accuracy: 0.3381\n",
      "Epoch 548/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1341 - accuracy: 0.6642 - val_loss: 4.5114 - val_accuracy: 0.3356\n",
      "Epoch 549/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1403 - accuracy: 0.6648 - val_loss: 4.4714 - val_accuracy: 0.3374\n",
      "Epoch 550/650\n",
      "386/386 [==============================] - 165s 426ms/step - loss: 1.1365 - accuracy: 0.6693 - val_loss: 4.4632 - val_accuracy: 0.3356\n",
      "Saved model and history at epoch 550\n",
      "Epoch 551/650\n",
      "386/386 [==============================] - 164s 426ms/step - loss: 1.1538 - accuracy: 0.6631 - val_loss: 4.5428 - val_accuracy: 0.3374\n",
      "Epoch 552/650\n",
      "386/386 [==============================] - 165s 426ms/step - loss: 1.1412 - accuracy: 0.6640 - val_loss: 4.4644 - val_accuracy: 0.3409\n",
      "Epoch 553/650\n",
      "386/386 [==============================] - 164s 425ms/step - loss: 1.1445 - accuracy: 0.6569 - val_loss: 4.4125 - val_accuracy: 0.3342\n",
      "Epoch 554/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1101 - accuracy: 0.6688 - val_loss: 4.4976 - val_accuracy: 0.3306\n",
      "Epoch 555/650\n",
      "386/386 [==============================] - 164s 425ms/step - loss: 1.1225 - accuracy: 0.6691 - val_loss: 4.6466 - val_accuracy: 0.3242\n",
      "Epoch 556/650\n",
      "386/386 [==============================] - 164s 426ms/step - loss: 1.1441 - accuracy: 0.6625 - val_loss: 4.4646 - val_accuracy: 0.3324\n",
      "Epoch 557/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1587 - accuracy: 0.6565 - val_loss: 4.5245 - val_accuracy: 0.3278\n",
      "Epoch 558/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1242 - accuracy: 0.6697 - val_loss: 4.6381 - val_accuracy: 0.3239\n",
      "Epoch 559/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1510 - accuracy: 0.6618 - val_loss: 4.5606 - val_accuracy: 0.3228\n",
      "Epoch 560/650\n",
      "386/386 [==============================] - 165s 426ms/step - loss: 1.1373 - accuracy: 0.6675 - val_loss: 4.5167 - val_accuracy: 0.3299\n",
      "Saved model and history at epoch 560\n",
      "Epoch 561/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1553 - accuracy: 0.6584 - val_loss: 4.5097 - val_accuracy: 0.3327\n",
      "Epoch 562/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1421 - accuracy: 0.6613 - val_loss: 4.4875 - val_accuracy: 0.3313\n",
      "Epoch 563/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1482 - accuracy: 0.6577 - val_loss: 4.2371 - val_accuracy: 0.3413\n",
      "Epoch 564/650\n",
      "386/386 [==============================] - 166s 429ms/step - loss: 1.1231 - accuracy: 0.6679 - val_loss: 4.3936 - val_accuracy: 0.3409\n",
      "Epoch 565/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1384 - accuracy: 0.6653 - val_loss: 4.4470 - val_accuracy: 0.3431\n",
      "Epoch 566/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1364 - accuracy: 0.6663 - val_loss: 4.4648 - val_accuracy: 0.3438\n",
      "Epoch 567/650\n",
      "386/386 [==============================] - 165s 426ms/step - loss: 1.1211 - accuracy: 0.6688 - val_loss: 4.4554 - val_accuracy: 0.3367\n",
      "Epoch 568/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1113 - accuracy: 0.6739 - val_loss: 4.5031 - val_accuracy: 0.3342\n",
      "Epoch 569/650\n",
      "386/386 [==============================] - 165s 427ms/step - loss: 1.1466 - accuracy: 0.6638 - val_loss: 4.5102 - val_accuracy: 0.3349\n",
      "Epoch 570/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1231 - accuracy: 0.6680 - val_loss: 4.5009 - val_accuracy: 0.3345\n",
      "Saved model and history at epoch 570\n",
      "Epoch 571/650\n",
      "386/386 [==============================] - 166s 428ms/step - loss: 1.1406 - accuracy: 0.6620 - val_loss: 4.5417 - val_accuracy: 0.3345\n",
      "Epoch 572/650\n",
      "386/386 [==============================] - 165s 428ms/step - loss: 1.1323 - accuracy: 0.6663 - val_loss: 4.4942 - val_accuracy: 0.3338\n",
      "Epoch 573/650\n",
      "386/386 [==============================] - 166s 430ms/step - loss: 1.1235 - accuracy: 0.6653 - val_loss: 4.4578 - val_accuracy: 0.3370\n",
      "Epoch 574/650\n",
      "386/386 [==============================] - 166s 429ms/step - loss: 1.1312 - accuracy: 0.6681 - val_loss: 4.2857 - val_accuracy: 0.3491\n",
      "Epoch 575/650\n",
      "386/386 [==============================] - 166s 430ms/step - loss: 1.1316 - accuracy: 0.6653 - val_loss: 4.4152 - val_accuracy: 0.3420\n",
      "Epoch 576/650\n",
      "386/386 [==============================] - 166s 430ms/step - loss: 1.0930 - accuracy: 0.6745 - val_loss: 4.5799 - val_accuracy: 0.3352\n",
      "Epoch 577/650\n",
      "386/386 [==============================] - 166s 431ms/step - loss: 1.1232 - accuracy: 0.6700 - val_loss: 4.4588 - val_accuracy: 0.3381\n",
      "Epoch 578/650\n",
      "386/386 [==============================] - 166s 430ms/step - loss: 1.1091 - accuracy: 0.6748 - val_loss: 4.5822 - val_accuracy: 0.3327\n",
      "Epoch 579/650\n",
      "386/386 [==============================] - 167s 431ms/step - loss: 1.1024 - accuracy: 0.6773 - val_loss: 4.4350 - val_accuracy: 0.3420\n",
      "Epoch 580/650\n",
      "386/386 [==============================] - 167s 433ms/step - loss: 1.0983 - accuracy: 0.6778 - val_loss: 4.6727 - val_accuracy: 0.3327\n",
      "Saved model and history at epoch 580\n",
      "Epoch 581/650\n",
      "386/386 [==============================] - 167s 433ms/step - loss: 1.1093 - accuracy: 0.6748 - val_loss: 4.7492 - val_accuracy: 0.3281\n",
      "Epoch 582/650\n",
      "386/386 [==============================] - 168s 433ms/step - loss: 1.1129 - accuracy: 0.6699 - val_loss: 4.4753 - val_accuracy: 0.3399\n",
      "Epoch 583/650\n",
      "386/386 [==============================] - 168s 435ms/step - loss: 1.1071 - accuracy: 0.6736 - val_loss: 4.4591 - val_accuracy: 0.3420\n",
      "Epoch 584/650\n",
      "386/386 [==============================] - 168s 436ms/step - loss: 1.1008 - accuracy: 0.6758 - val_loss: 4.4549 - val_accuracy: 0.3413\n",
      "Epoch 585/650\n",
      "386/386 [==============================] - 169s 438ms/step - loss: 1.0871 - accuracy: 0.6786 - val_loss: 4.5400 - val_accuracy: 0.3370\n",
      "Epoch 586/650\n",
      "386/386 [==============================] - 169s 438ms/step - loss: 1.1104 - accuracy: 0.6704 - val_loss: 4.5627 - val_accuracy: 0.3363\n",
      "Epoch 587/650\n",
      "386/386 [==============================] - 170s 440ms/step - loss: 1.1175 - accuracy: 0.6703 - val_loss: 4.4642 - val_accuracy: 0.3342\n",
      "Epoch 588/650\n",
      "386/386 [==============================] - 170s 440ms/step - loss: 1.0937 - accuracy: 0.6784 - val_loss: 4.3801 - val_accuracy: 0.3338\n",
      "Epoch 589/650\n",
      "386/386 [==============================] - 171s 443ms/step - loss: 1.1047 - accuracy: 0.6742 - val_loss: 4.5734 - val_accuracy: 0.3345\n",
      "Epoch 590/650\n",
      "386/386 [==============================] - 277s 719ms/step - loss: 1.0972 - accuracy: 0.6756 - val_loss: 4.5759 - val_accuracy: 0.3239\n",
      "Saved model and history at epoch 590\n",
      "Epoch 591/650\n",
      "386/386 [==============================] - 423s 1s/step - loss: 1.1070 - accuracy: 0.6752 - val_loss: 4.5926 - val_accuracy: 0.3267\n",
      "Epoch 592/650\n",
      "386/386 [==============================] - 184s 475ms/step - loss: 1.1042 - accuracy: 0.6761 - val_loss: 4.5511 - val_accuracy: 0.3292\n",
      "Epoch 593/650\n",
      "386/386 [==============================] - 194s 503ms/step - loss: 1.1004 - accuracy: 0.6768 - val_loss: 4.6211 - val_accuracy: 0.3295\n",
      "Epoch 594/650\n",
      "386/386 [==============================] - 199s 516ms/step - loss: 1.0995 - accuracy: 0.6761 - val_loss: 4.4134 - val_accuracy: 0.3363\n",
      "Epoch 595/650\n",
      "386/386 [==============================] - 186s 482ms/step - loss: 1.1008 - accuracy: 0.6752 - val_loss: 4.5862 - val_accuracy: 0.3303\n",
      "Epoch 596/650\n",
      "386/386 [==============================] - 187s 482ms/step - loss: 1.1157 - accuracy: 0.6668 - val_loss: 4.5985 - val_accuracy: 0.3281\n",
      "Epoch 597/650\n",
      "386/386 [==============================] - 204s 528ms/step - loss: 1.0874 - accuracy: 0.6861 - val_loss: 4.4208 - val_accuracy: 0.3434\n",
      "Epoch 598/650\n",
      "386/386 [==============================] - 204s 527ms/step - loss: 1.1018 - accuracy: 0.6748 - val_loss: 4.6017 - val_accuracy: 0.3363\n",
      "Epoch 599/650\n",
      "386/386 [==============================] - 190s 492ms/step - loss: 1.0892 - accuracy: 0.6794 - val_loss: 4.5601 - val_accuracy: 0.3317\n",
      "Epoch 600/650\n",
      "386/386 [==============================] - 191s 494ms/step - loss: 1.0776 - accuracy: 0.6839 - val_loss: 4.5045 - val_accuracy: 0.3388\n",
      "Saved model and history at epoch 600\n",
      "Epoch 601/650\n",
      "386/386 [==============================] - 195s 503ms/step - loss: 1.1042 - accuracy: 0.6793 - val_loss: 4.4358 - val_accuracy: 0.3359\n",
      "Epoch 602/650\n",
      "386/386 [==============================] - 203s 525ms/step - loss: 1.0979 - accuracy: 0.6728 - val_loss: 4.4893 - val_accuracy: 0.3313\n",
      "Epoch 603/650\n",
      "386/386 [==============================] - 214s 554ms/step - loss: 1.0962 - accuracy: 0.6780 - val_loss: 4.6043 - val_accuracy: 0.3384\n",
      "Epoch 604/650\n",
      "386/386 [==============================] - 216s 558ms/step - loss: 1.1008 - accuracy: 0.6783 - val_loss: 4.5822 - val_accuracy: 0.3274\n",
      "Epoch 605/650\n",
      "386/386 [==============================] - 216s 559ms/step - loss: 1.0854 - accuracy: 0.6766 - val_loss: 4.4305 - val_accuracy: 0.3384\n",
      "Epoch 606/650\n",
      "386/386 [==============================] - 215s 556ms/step - loss: 1.0780 - accuracy: 0.6818 - val_loss: 4.5274 - val_accuracy: 0.3349\n",
      "Epoch 607/650\n",
      "386/386 [==============================] - 525s 1s/step - loss: 1.0878 - accuracy: 0.6837 - val_loss: 4.5018 - val_accuracy: 0.3409\n",
      "Epoch 608/650\n",
      "386/386 [==============================] - 225s 583ms/step - loss: 1.0890 - accuracy: 0.6797 - val_loss: 4.5558 - val_accuracy: 0.3434\n",
      "Epoch 609/650\n",
      "386/386 [==============================] - 214s 554ms/step - loss: 1.0734 - accuracy: 0.6769 - val_loss: 4.5515 - val_accuracy: 0.3406\n",
      "Epoch 610/650\n",
      "386/386 [==============================] - 215s 557ms/step - loss: 1.0818 - accuracy: 0.6786 - val_loss: 4.6328 - val_accuracy: 0.3370\n",
      "Saved model and history at epoch 610\n",
      "Epoch 611/650\n",
      "386/386 [==============================] - 215s 557ms/step - loss: 1.0726 - accuracy: 0.6816 - val_loss: 4.5867 - val_accuracy: 0.3423\n",
      "Epoch 612/650\n",
      "386/386 [==============================] - 214s 555ms/step - loss: 1.0856 - accuracy: 0.6808 - val_loss: 4.5280 - val_accuracy: 0.3409\n",
      "Epoch 613/650\n",
      "386/386 [==============================] - 214s 554ms/step - loss: 1.0922 - accuracy: 0.6759 - val_loss: 4.6678 - val_accuracy: 0.3320\n",
      "Epoch 614/650\n",
      "386/386 [==============================] - 214s 554ms/step - loss: 1.0632 - accuracy: 0.6820 - val_loss: 4.6515 - val_accuracy: 0.3327\n",
      "Epoch 615/650\n",
      "386/386 [==============================] - 217s 561ms/step - loss: 1.0842 - accuracy: 0.6793 - val_loss: 4.5240 - val_accuracy: 0.3427\n",
      "Epoch 616/650\n",
      "386/386 [==============================] - 218s 564ms/step - loss: 1.0906 - accuracy: 0.6800 - val_loss: 4.6637 - val_accuracy: 0.3359\n",
      "Epoch 617/650\n",
      "386/386 [==============================] - 218s 563ms/step - loss: 1.0740 - accuracy: 0.6837 - val_loss: 4.5451 - val_accuracy: 0.3377\n",
      "Epoch 618/650\n",
      "386/386 [==============================] - 218s 565ms/step - loss: 1.0677 - accuracy: 0.6834 - val_loss: 4.4510 - val_accuracy: 0.3466\n",
      "Epoch 619/650\n",
      "386/386 [==============================] - 218s 563ms/step - loss: 1.0675 - accuracy: 0.6844 - val_loss: 4.7028 - val_accuracy: 0.3303\n",
      "Epoch 620/650\n",
      "386/386 [==============================] - 218s 563ms/step - loss: 1.0598 - accuracy: 0.6876 - val_loss: 4.5891 - val_accuracy: 0.3427\n",
      "Saved model and history at epoch 620\n",
      "Epoch 621/650\n",
      "386/386 [==============================] - 224s 579ms/step - loss: 1.0689 - accuracy: 0.6829 - val_loss: 4.6291 - val_accuracy: 0.3391\n",
      "Epoch 622/650\n",
      "386/386 [==============================] - 213s 550ms/step - loss: 1.0716 - accuracy: 0.6850 - val_loss: 4.6494 - val_accuracy: 0.3406\n",
      "Epoch 623/650\n",
      "386/386 [==============================] - 203s 525ms/step - loss: 1.0583 - accuracy: 0.6851 - val_loss: 4.5732 - val_accuracy: 0.3391\n",
      "Epoch 624/650\n",
      "386/386 [==============================] - 220s 568ms/step - loss: 1.0754 - accuracy: 0.6808 - val_loss: 4.6482 - val_accuracy: 0.3327\n",
      "Epoch 625/650\n",
      "386/386 [==============================] - 221s 571ms/step - loss: 1.0745 - accuracy: 0.6799 - val_loss: 4.5252 - val_accuracy: 0.3438\n",
      "Epoch 626/650\n",
      "386/386 [==============================] - 211s 546ms/step - loss: 1.0519 - accuracy: 0.6926 - val_loss: 4.3516 - val_accuracy: 0.3566\n",
      "Epoch 627/650\n",
      "386/386 [==============================] - 226s 585ms/step - loss: 1.0653 - accuracy: 0.6833 - val_loss: 4.5711 - val_accuracy: 0.3409\n",
      "Epoch 628/650\n",
      "386/386 [==============================] - 252s 653ms/step - loss: 1.0554 - accuracy: 0.6882 - val_loss: 4.6973 - val_accuracy: 0.3327\n",
      "Epoch 629/650\n",
      "386/386 [==============================] - 229s 591ms/step - loss: 1.0786 - accuracy: 0.6789 - val_loss: 4.5646 - val_accuracy: 0.3391\n",
      "Epoch 630/650\n",
      "386/386 [==============================] - 226s 585ms/step - loss: 1.0504 - accuracy: 0.6887 - val_loss: 4.5200 - val_accuracy: 0.3491\n",
      "Saved model and history at epoch 630\n",
      "Epoch 631/650\n",
      "386/386 [==============================] - 223s 577ms/step - loss: 1.0718 - accuracy: 0.6829 - val_loss: 4.6653 - val_accuracy: 0.3391\n",
      "Epoch 632/650\n",
      "386/386 [==============================] - 223s 577ms/step - loss: 1.0590 - accuracy: 0.6842 - val_loss: 4.5734 - val_accuracy: 0.3452\n",
      "Epoch 633/650\n",
      "386/386 [==============================] - 223s 576ms/step - loss: 1.0466 - accuracy: 0.6912 - val_loss: 4.6499 - val_accuracy: 0.3356\n",
      "Epoch 634/650\n",
      "386/386 [==============================] - 227s 588ms/step - loss: 1.0435 - accuracy: 0.6902 - val_loss: 4.7637 - val_accuracy: 0.3363\n",
      "Epoch 635/650\n",
      "386/386 [==============================] - 227s 587ms/step - loss: 1.0792 - accuracy: 0.6819 - val_loss: 4.5124 - val_accuracy: 0.3420\n",
      "Epoch 636/650\n",
      "386/386 [==============================] - 228s 589ms/step - loss: 1.0648 - accuracy: 0.6918 - val_loss: 4.5878 - val_accuracy: 0.3356\n",
      "Epoch 637/650\n",
      "386/386 [==============================] - 223s 578ms/step - loss: 1.0526 - accuracy: 0.6879 - val_loss: 4.7068 - val_accuracy: 0.3256\n",
      "Epoch 638/650\n",
      "386/386 [==============================] - 237s 614ms/step - loss: 1.0638 - accuracy: 0.6843 - val_loss: 4.7444 - val_accuracy: 0.3303\n",
      "Epoch 639/650\n",
      "386/386 [==============================] - 234s 604ms/step - loss: 1.0597 - accuracy: 0.6869 - val_loss: 4.7088 - val_accuracy: 0.3303\n",
      "Epoch 640/650\n",
      "386/386 [==============================] - 231s 598ms/step - loss: 1.0646 - accuracy: 0.6882 - val_loss: 4.7800 - val_accuracy: 0.3299\n",
      "Saved model and history at epoch 640\n",
      "Epoch 641/650\n",
      "386/386 [==============================] - 239s 618ms/step - loss: 1.0402 - accuracy: 0.6963 - val_loss: 4.6826 - val_accuracy: 0.3370\n",
      "Epoch 642/650\n",
      "386/386 [==============================] - 241s 625ms/step - loss: 1.0558 - accuracy: 0.6956 - val_loss: 4.6871 - val_accuracy: 0.3338\n",
      "Epoch 643/650\n",
      "386/386 [==============================] - 235s 607ms/step - loss: 1.0401 - accuracy: 0.6938 - val_loss: 4.6435 - val_accuracy: 0.3260\n",
      "Epoch 644/650\n",
      "386/386 [==============================] - 234s 605ms/step - loss: 1.0530 - accuracy: 0.6878 - val_loss: 4.6188 - val_accuracy: 0.3370\n",
      "Epoch 645/650\n",
      "386/386 [==============================] - 230s 596ms/step - loss: 1.0690 - accuracy: 0.6913 - val_loss: 4.6235 - val_accuracy: 0.3349\n",
      "Epoch 646/650\n",
      "386/386 [==============================] - 228s 588ms/step - loss: 1.0700 - accuracy: 0.6880 - val_loss: 4.6655 - val_accuracy: 0.3320\n",
      "Epoch 647/650\n",
      "386/386 [==============================] - 239s 619ms/step - loss: 1.0445 - accuracy: 0.6883 - val_loss: 4.6820 - val_accuracy: 0.3313\n",
      "Epoch 648/650\n",
      "386/386 [==============================] - 239s 617ms/step - loss: 1.0373 - accuracy: 0.6915 - val_loss: 4.6319 - val_accuracy: 0.3320\n",
      "Epoch 649/650\n",
      "386/386 [==============================] - 239s 619ms/step - loss: 1.0573 - accuracy: 0.6854 - val_loss: 4.7652 - val_accuracy: 0.3256\n",
      "Epoch 650/650\n",
      "386/386 [==============================] - 233s 603ms/step - loss: 1.0518 - accuracy: 0.6902 - val_loss: 4.7461 - val_accuracy: 0.3374\n",
      "Saved model and history at epoch 650\n"
     ]
    }
   ],
   "source": [
    "saKOJHSDJHKahskjA\n",
    "# train_and_save(\n",
    "#     model, \n",
    "#     training_generator, \n",
    "#     validation_generator, \n",
    "#     epochs=150, \n",
    "#     save_interval=10, \n",
    "#     model_save_path=\"models\", \n",
    "#     history_save_path=\"history.csv\", \n",
    "#     custom_metrics=[],\n",
    "#     custom_optimizer=opt\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2871/2871 [==============================] - 119s 41ms/step - loss: 4.8088 - accuracy: 0.3285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.808804035186768, 0.32845696806907654]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "model = tf.keras.models.load_model('models/model_e650.h5')\n",
    "\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2871/2871 [==============================] - 33s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "\n",
    "predicted_labels = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(test_generator.classes, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Predicted Labels: %{x}<br>True Labels: %{y}<br>Normalized Confusion: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38
         ],
         "xaxis": "x",
         "y": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38
         ],
         "yaxis": "y",
         "z": [
          [
           0.23076923076923078,
           0.038461538461538464,
           0.038461538461538464,
           0.05128205128205128,
           0,
           0,
           0.02564102564102564,
           0,
           0.038461538461538464,
           0.01282051282051282,
           0.0641025641025641,
           0,
           0.02564102564102564,
           0.01282051282051282,
           0.05128205128205128,
           0,
           0.01282051282051282,
           0.02564102564102564,
           0,
           0.01282051282051282,
           0.038461538461538464,
           0.038461538461538464,
           0.01282051282051282,
           0.038461538461538464,
           0,
           0,
           0,
           0.01282051282051282,
           0.01282051282051282,
           0.02564102564102564,
           0.02564102564102564,
           0,
           0.038461538461538464,
           0.01282051282051282,
           0,
           0.02564102564102564,
           0.038461538461538464,
           0,
           0.038461538461538464
          ],
          [
           0.02,
           0.54,
           0.01,
           0.02,
           0.01,
           0.01,
           0,
           0,
           0.02,
           0.02,
           0.02,
           0,
           0,
           0,
           0.03,
           0.01,
           0.01,
           0,
           0.03,
           0,
           0.05,
           0.03,
           0.02,
           0.02,
           0,
           0,
           0.02,
           0.02,
           0.01,
           0,
           0.01,
           0,
           0.01,
           0.01,
           0.01,
           0.01,
           0.01,
           0.02,
           0
          ],
          [
           0,
           0.011363636363636364,
           0.48863636363636365,
           0.056818181818181816,
           0.011363636363636364,
           0,
           0,
           0,
           0,
           0.022727272727272728,
           0,
           0,
           0.011363636363636364,
           0.03409090909090909,
           0,
           0.022727272727272728,
           0,
           0,
           0.011363636363636364,
           0.011363636363636364,
           0.022727272727272728,
           0,
           0.056818181818181816,
           0.03409090909090909,
           0.011363636363636364,
           0,
           0,
           0.011363636363636364,
           0,
           0.011363636363636364,
           0.022727272727272728,
           0,
           0,
           0.011363636363636364,
           0,
           0,
           0.06818181818181818,
           0.022727272727272728,
           0.045454545454545456
          ],
          [
           0,
           0.022988505747126436,
           0.04597701149425287,
           0.5402298850574713,
           0.022988505747126436,
           0.011494252873563218,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.034482758620689655,
           0.011494252873563218,
           0,
           0.034482758620689655,
           0,
           0,
           0.011494252873563218,
           0.011494252873563218,
           0.011494252873563218,
           0.034482758620689655,
           0.04597701149425287,
           0,
           0,
           0.022988505747126436,
           0.022988505747126436,
           0,
           0,
           0.022988505747126436,
           0,
           0,
           0.011494252873563218,
           0.011494252873563218,
           0.011494252873563218,
           0.011494252873563218,
           0,
           0.04597701149425287
          ],
          [
           0.01639344262295082,
           0,
           0.03278688524590164,
           0.09836065573770492,
           0.5573770491803278,
           0,
           0.01639344262295082,
           0,
           0,
           0.01639344262295082,
           0,
           0,
           0,
           0,
           0.03278688524590164,
           0,
           0.03278688524590164,
           0,
           0.01639344262295082,
           0,
           0.01639344262295082,
           0,
           0.08196721311475409,
           0.04918032786885246,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.01639344262295082,
           0,
           0.01639344262295082,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0.015625,
           0.015625,
           0.28125,
           0,
           0.046875,
           0,
           0,
           0.046875,
           0.015625,
           0.015625,
           0.015625,
           0,
           0,
           0.046875,
           0.03125,
           0,
           0.03125,
           0,
           0.015625,
           0.03125,
           0.015625,
           0.03125,
           0,
           0.046875,
           0,
           0.046875,
           0.03125,
           0.046875,
           0,
           0.015625,
           0.015625,
           0.03125,
           0.046875,
           0.03125,
           0,
           0.03125
          ],
          [
           0.02702702702702703,
           0,
           0.05405405405405406,
           0.05405405405405406,
           0,
           0,
           0.32432432432432434,
           0,
           0,
           0,
           0.02702702702702703,
           0.02702702702702703,
           0,
           0,
           0,
           0,
           0,
           0.05405405405405406,
           0,
           0.02702702702702703,
           0.02702702702702703,
           0.02702702702702703,
           0.02702702702702703,
           0,
           0,
           0.05405405405405406,
           0.08108108108108109,
           0,
           0.02702702702702703,
           0.05405405405405406,
           0.02702702702702703,
           0,
           0,
           0,
           0,
           0,
           0,
           0.02702702702702703,
           0.05405405405405406
          ],
          [
           0.016666666666666666,
           0.016666666666666666,
           0,
           0,
           0,
           0.05,
           0,
           0.26666666666666666,
           0,
           0,
           0.016666666666666666,
           0,
           0.016666666666666666,
           0.05,
           0,
           0.016666666666666666,
           0.1,
           0,
           0.016666666666666666,
           0.016666666666666666,
           0.016666666666666666,
           0,
           0.016666666666666666,
           0.016666666666666666,
           0.016666666666666666,
           0,
           0.05,
           0,
           0.016666666666666666,
           0.05,
           0.03333333333333333,
           0.016666666666666666,
           0.016666666666666666,
           0.05,
           0.016666666666666666,
           0.03333333333333333,
           0.03333333333333333,
           0.016666666666666666,
           0.016666666666666666
          ],
          [
           0.057692307692307696,
           0.019230769230769232,
           0,
           0.019230769230769232,
           0,
           0.038461538461538464,
           0,
           0.019230769230769232,
           0.17307692307692307,
           0.038461538461538464,
           0,
           0,
           0.07692307692307693,
           0.057692307692307696,
           0,
           0,
           0.019230769230769232,
           0,
           0,
           0,
           0,
           0.038461538461538464,
           0,
           0.019230769230769232,
           0.019230769230769232,
           0,
           0.038461538461538464,
           0,
           0.038461538461538464,
           0.019230769230769232,
           0.057692307692307696,
           0,
           0.057692307692307696,
           0,
           0,
           0.038461538461538464,
           0.057692307692307696,
           0.057692307692307696,
           0.038461538461538464
          ],
          [
           0.033707865168539325,
           0.02247191011235955,
           0.011235955056179775,
           0.033707865168539325,
           0.02247191011235955,
           0.011235955056179775,
           0.0449438202247191,
           0,
           0,
           0.34831460674157305,
           0.011235955056179775,
           0.011235955056179775,
           0.011235955056179775,
           0,
           0.02247191011235955,
           0.033707865168539325,
           0,
           0.02247191011235955,
           0.033707865168539325,
           0,
           0.02247191011235955,
           0.02247191011235955,
           0.033707865168539325,
           0.011235955056179775,
           0.056179775280898875,
           0.011235955056179775,
           0.011235955056179775,
           0.011235955056179775,
           0,
           0,
           0.033707865168539325,
           0.011235955056179775,
           0,
           0.011235955056179775,
           0.011235955056179775,
           0.033707865168539325,
           0.011235955056179775,
           0,
           0.033707865168539325
          ],
          [
           0.038461538461538464,
           0,
           0.038461538461538464,
           0,
           0,
           0,
           0,
           0.01282051282051282,
           0,
           0.01282051282051282,
           0.28205128205128205,
           0.01282051282051282,
           0.038461538461538464,
           0.038461538461538464,
           0.01282051282051282,
           0.01282051282051282,
           0.038461538461538464,
           0.01282051282051282,
           0.038461538461538464,
           0,
           0.01282051282051282,
           0,
           0.01282051282051282,
           0.038461538461538464,
           0.02564102564102564,
           0.01282051282051282,
           0.02564102564102564,
           0,
           0.01282051282051282,
           0.01282051282051282,
           0.038461538461538464,
           0.02564102564102564,
           0.01282051282051282,
           0.01282051282051282,
           0,
           0.05128205128205128,
           0.038461538461538464,
           0.05128205128205128,
           0.02564102564102564
          ],
          [
           0.03333333333333333,
           0.05,
           0.06666666666666667,
           0.05,
           0.03333333333333333,
           0.03333333333333333,
           0,
           0,
           0.03333333333333333,
           0.016666666666666666,
           0.03333333333333333,
           0.08333333333333333,
           0.016666666666666666,
           0.03333333333333333,
           0,
           0.016666666666666666,
           0.11666666666666667,
           0,
           0,
           0.03333333333333333,
           0.016666666666666666,
           0,
           0,
           0.06666666666666667,
           0,
           0,
           0.016666666666666666,
           0,
           0.016666666666666666,
           0,
           0.03333333333333333,
           0,
           0.05,
           0,
           0.016666666666666666,
           0.1,
           0.016666666666666666,
           0.016666666666666666,
           0
          ],
          [
           0.02631578947368421,
           0,
           0.013157894736842105,
           0.039473684210526314,
           0.039473684210526314,
           0.039473684210526314,
           0.013157894736842105,
           0.013157894736842105,
           0,
           0.02631578947368421,
           0.013157894736842105,
           0.013157894736842105,
           0.18421052631578946,
           0.013157894736842105,
           0,
           0.013157894736842105,
           0.039473684210526314,
           0.039473684210526314,
           0.02631578947368421,
           0.02631578947368421,
           0,
           0,
           0.05263157894736842,
           0.013157894736842105,
           0.013157894736842105,
           0.02631578947368421,
           0.013157894736842105,
           0,
           0.013157894736842105,
           0,
           0.013157894736842105,
           0,
           0,
           0.039473684210526314,
           0,
           0.07894736842105263,
           0.13157894736842105,
           0.02631578947368421,
           0
          ],
          [
           0,
           0.01282051282051282,
           0.01282051282051282,
           0.05128205128205128,
           0.01282051282051282,
           0.02564102564102564,
           0,
           0,
           0.01282051282051282,
           0,
           0.038461538461538464,
           0.01282051282051282,
           0.038461538461538464,
           0.2564102564102564,
           0,
           0.01282051282051282,
           0.0641025641025641,
           0,
           0.11538461538461539,
           0,
           0,
           0,
           0.0641025641025641,
           0.02564102564102564,
           0.02564102564102564,
           0,
           0.038461538461538464,
           0,
           0,
           0.038461538461538464,
           0.02564102564102564,
           0,
           0.01282051282051282,
           0.01282051282051282,
           0,
           0,
           0.0641025641025641,
           0.01282051282051282,
           0.01282051282051282
          ],
          [
           0.030612244897959183,
           0.030612244897959183,
           0.02040816326530612,
           0.08163265306122448,
           0.061224489795918366,
           0.02040816326530612,
           0.01020408163265306,
           0,
           0,
           0,
           0,
           0,
           0.01020408163265306,
           0,
           0.3163265306122449,
           0.01020408163265306,
           0.01020408163265306,
           0.01020408163265306,
           0.030612244897959183,
           0.04081632653061224,
           0.04081632653061224,
           0,
           0,
           0.02040816326530612,
           0,
           0.02040816326530612,
           0,
           0.02040816326530612,
           0.02040816326530612,
           0.01020408163265306,
           0.05102040816326531,
           0,
           0,
           0,
           0.04081632653061224,
           0.01020408163265306,
           0.01020408163265306,
           0.04081632653061224,
           0.030612244897959183
          ],
          [
           0.018867924528301886,
           0,
           0.018867924528301886,
           0.09433962264150944,
           0.05660377358490566,
           0.018867924528301886,
           0,
           0.018867924528301886,
           0.018867924528301886,
           0,
           0.03773584905660377,
           0,
           0,
           0,
           0.018867924528301886,
           0.3584905660377358,
           0,
           0.03773584905660377,
           0.03773584905660377,
           0.018867924528301886,
           0,
           0,
           0.05660377358490566,
           0.018867924528301886,
           0.018867924528301886,
           0,
           0.03773584905660377,
           0,
           0.03773584905660377,
           0,
           0.018867924528301886,
           0,
           0.03773584905660377,
           0,
           0,
           0,
           0.018867924528301886,
           0,
           0
          ],
          [
           0,
           0.02531645569620253,
           0,
           0.02531645569620253,
           0.02531645569620253,
           0.06329113924050633,
           0,
           0,
           0,
           0.0379746835443038,
           0,
           0,
           0.02531645569620253,
           0,
           0,
           0,
           0.3924050632911392,
           0.02531645569620253,
           0.02531645569620253,
           0.012658227848101266,
           0,
           0.02531645569620253,
           0.02531645569620253,
           0.02531645569620253,
           0,
           0.012658227848101266,
           0.02531645569620253,
           0,
           0,
           0.012658227848101266,
           0.0379746835443038,
           0,
           0,
           0.02531645569620253,
           0.012658227848101266,
           0.06329113924050633,
           0.06329113924050633,
           0,
           0.012658227848101266
          ],
          [
           0,
           0.024096385542168676,
           0.024096385542168676,
           0.024096385542168676,
           0.024096385542168676,
           0.012048192771084338,
           0,
           0.012048192771084338,
           0,
           0,
           0,
           0.012048192771084338,
           0.024096385542168676,
           0.03614457831325301,
           0.024096385542168676,
           0,
           0.07228915662650602,
           0.39759036144578314,
           0.024096385542168676,
           0,
           0.024096385542168676,
           0,
           0,
           0.012048192771084338,
           0.03614457831325301,
           0,
           0.04819277108433735,
           0.04819277108433735,
           0,
           0,
           0.012048192771084338,
           0.012048192771084338,
           0.012048192771084338,
           0.03614457831325301,
           0,
           0.024096385542168676,
           0,
           0.012048192771084338,
           0.012048192771084338
          ],
          [
           0,
           0.019801980198019802,
           0.04950495049504951,
           0.0594059405940594,
           0.019801980198019802,
           0,
           0,
           0.009900990099009901,
           0,
           0.009900990099009901,
           0.009900990099009901,
           0.009900990099009901,
           0.009900990099009901,
           0.019801980198019802,
           0.0297029702970297,
           0,
           0.009900990099009901,
           0,
           0.42574257425742573,
           0.009900990099009901,
           0.019801980198019802,
           0.04950495049504951,
           0.04950495049504951,
           0,
           0.009900990099009901,
           0.009900990099009901,
           0.019801980198019802,
           0.009900990099009901,
           0,
           0,
           0.0297029702970297,
           0,
           0.009900990099009901,
           0,
           0,
           0.04950495049504951,
           0.0297029702970297,
           0.009900990099009901,
           0.009900990099009901
          ],
          [
           0,
           0.017857142857142856,
           0,
           0.017857142857142856,
           0.03571428571428571,
           0.017857142857142856,
           0.017857142857142856,
           0.017857142857142856,
           0.017857142857142856,
           0.03571428571428571,
           0.017857142857142856,
           0,
           0.017857142857142856,
           0.03571428571428571,
           0.017857142857142856,
           0,
           0.03571428571428571,
           0,
           0.03571428571428571,
           0.4107142857142857,
           0,
           0,
           0,
           0,
           0.017857142857142856,
           0,
           0.03571428571428571,
           0,
           0,
           0,
           0.017857142857142856,
           0,
           0.017857142857142856,
           0,
           0,
           0.07142857142857142,
           0.05357142857142857,
           0.03571428571428571,
           0
          ],
          [
           0.015873015873015872,
           0.06349206349206349,
           0.015873015873015872,
           0.047619047619047616,
           0.06349206349206349,
           0,
           0.015873015873015872,
           0,
           0,
           0,
           0,
           0.015873015873015872,
           0,
           0,
           0.031746031746031744,
           0.031746031746031744,
           0.031746031746031744,
           0,
           0,
           0,
           0.4444444444444444,
           0.015873015873015872,
           0,
           0,
           0,
           0,
           0.031746031746031744,
           0.031746031746031744,
           0,
           0,
           0.031746031746031744,
           0.015873015873015872,
           0.031746031746031744,
           0,
           0.015873015873015872,
           0,
           0,
           0.015873015873015872,
           0.031746031746031744
          ],
          [
           0.010869565217391304,
           0.03260869565217391,
           0.043478260869565216,
           0,
           0.010869565217391304,
           0,
           0,
           0.010869565217391304,
           0.021739130434782608,
           0.010869565217391304,
           0.03260869565217391,
           0.010869565217391304,
           0.08695652173913043,
           0.03260869565217391,
           0,
           0.021739130434782608,
           0.021739130434782608,
           0.010869565217391304,
           0.06521739130434782,
           0.021739130434782608,
           0.010869565217391304,
           0.2717391304347826,
           0.021739130434782608,
           0.010869565217391304,
           0,
           0.010869565217391304,
           0.010869565217391304,
           0.010869565217391304,
           0.010869565217391304,
           0,
           0.021739130434782608,
           0,
           0.043478260869565216,
           0.010869565217391304,
           0,
           0.043478260869565216,
           0.03260869565217391,
           0.010869565217391304,
           0.03260869565217391
          ],
          [
           0,
           0.0078125,
           0.0390625,
           0.1015625,
           0.03125,
           0,
           0,
           0,
           0,
           0.0078125,
           0.0078125,
           0.015625,
           0.015625,
           0,
           0.0078125,
           0,
           0.0078125,
           0.0078125,
           0.0078125,
           0.0078125,
           0.03125,
           0,
           0.46875,
           0.03125,
           0,
           0,
           0.0390625,
           0.03125,
           0,
           0.0078125,
           0.0234375,
           0.0078125,
           0,
           0.0078125,
           0.015625,
           0.0078125,
           0.0390625,
           0.0078125,
           0.015625
          ],
          [
           0,
           0.02631578947368421,
           0.02631578947368421,
           0.07894736842105263,
           0.02631578947368421,
           0,
           0,
           0,
           0,
           0.02631578947368421,
           0.05263157894736842,
           0,
           0,
           0,
           0,
           0.02631578947368421,
           0.07894736842105263,
           0.02631578947368421,
           0,
           0,
           0.02631578947368421,
           0,
           0.07894736842105263,
           0.2894736842105263,
           0.02631578947368421,
           0,
           0,
           0.07894736842105263,
           0,
           0.02631578947368421,
           0,
           0.02631578947368421,
           0.02631578947368421,
           0,
           0,
           0,
           0.05263157894736842,
           0,
           0
          ],
          [
           0.028169014084507043,
           0.028169014084507043,
           0.028169014084507043,
           0,
           0,
           0,
           0,
           0.028169014084507043,
           0,
           0.014084507042253521,
           0,
           0.014084507042253521,
           0.07042253521126761,
           0.04225352112676056,
           0.028169014084507043,
           0.014084507042253521,
           0.014084507042253521,
           0.028169014084507043,
           0.056338028169014086,
           0.04225352112676056,
           0.04225352112676056,
           0.028169014084507043,
           0.014084507042253521,
           0.028169014084507043,
           0.07042253521126761,
           0.056338028169014086,
           0.028169014084507043,
           0,
           0.028169014084507043,
           0,
           0.04225352112676056,
           0.028169014084507043,
           0,
           0.028169014084507043,
           0.028169014084507043,
           0.028169014084507043,
           0.056338028169014086,
           0.04225352112676056,
           0.014084507042253521
          ],
          [
           0,
           0,
           0.03508771929824561,
           0.05263157894736842,
           0,
           0.017543859649122806,
           0,
           0,
           0,
           0,
           0.07017543859649122,
           0.03508771929824561,
           0.03508771929824561,
           0.05263157894736842,
           0,
           0,
           0.05263157894736842,
           0.03508771929824561,
           0.017543859649122806,
           0.03508771929824561,
           0,
           0.05263157894736842,
           0.03508771929824561,
           0.017543859649122806,
           0.017543859649122806,
           0.15789473684210525,
           0.05263157894736842,
           0.017543859649122806,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.07017543859649122,
           0.03508771929824561,
           0.07017543859649122,
           0.03508771929824561
          ],
          [
           0.012048192771084338,
           0.03614457831325301,
           0,
           0.012048192771084338,
           0,
           0.060240963855421686,
           0,
           0.012048192771084338,
           0,
           0.012048192771084338,
           0,
           0.012048192771084338,
           0.012048192771084338,
           0.012048192771084338,
           0.024096385542168676,
           0,
           0.08433734939759036,
           0.012048192771084338,
           0.012048192771084338,
           0,
           0,
           0,
           0.024096385542168676,
           0,
           0.024096385542168676,
           0,
           0.3132530120481928,
           0,
           0,
           0.04819277108433735,
           0.060240963855421686,
           0,
           0,
           0.03614457831325301,
           0,
           0.03614457831325301,
           0.0963855421686747,
           0.03614457831325301,
           0.012048192771084338
          ],
          [
           0.03488372093023256,
           0.05813953488372093,
           0.011627906976744186,
           0.046511627906976744,
           0,
           0.011627906976744186,
           0.023255813953488372,
           0.011627906976744186,
           0.011627906976744186,
           0.05813953488372093,
           0.03488372093023256,
           0.011627906976744186,
           0,
           0,
           0.011627906976744186,
           0,
           0,
           0.023255813953488372,
           0.011627906976744186,
           0,
           0.03488372093023256,
           0,
           0.06976744186046512,
           0.023255813953488372,
           0.011627906976744186,
           0.011627906976744186,
           0.023255813953488372,
           0.3488372093023256,
           0,
           0,
           0.03488372093023256,
           0,
           0.023255813953488372,
           0,
           0.023255813953488372,
           0.011627906976744186,
           0.011627906976744186,
           0,
           0.011627906976744186
          ],
          [
           0.031746031746031744,
           0.015873015873015872,
           0,
           0,
           0,
           0.07936507936507936,
           0,
           0,
           0,
           0.015873015873015872,
           0,
           0.015873015873015872,
           0.031746031746031744,
           0.015873015873015872,
           0.015873015873015872,
           0,
           0.031746031746031744,
           0.07936507936507936,
           0.015873015873015872,
           0.015873015873015872,
           0.031746031746031744,
           0.031746031746031744,
           0.015873015873015872,
           0,
           0,
           0,
           0.06349206349206349,
           0.015873015873015872,
           0.14285714285714285,
           0.031746031746031744,
           0.015873015873015872,
           0,
           0.031746031746031744,
           0.047619047619047616,
           0,
           0,
           0.047619047619047616,
           0.12698412698412698,
           0.031746031746031744
          ],
          [
           0,
           0,
           0.02564102564102564,
           0.02564102564102564,
           0,
           0.01282051282051282,
           0.01282051282051282,
           0.01282051282051282,
           0.038461538461538464,
           0,
           0.0641025641025641,
           0,
           0.038461538461538464,
           0.01282051282051282,
           0.01282051282051282,
           0,
           0.038461538461538464,
           0.01282051282051282,
           0,
           0.02564102564102564,
           0.01282051282051282,
           0.038461538461538464,
           0.02564102564102564,
           0.01282051282051282,
           0.01282051282051282,
           0.038461538461538464,
           0.038461538461538464,
           0,
           0,
           0.2564102564102564,
           0.08974358974358974,
           0.01282051282051282,
           0,
           0.01282051282051282,
           0.02564102564102564,
           0,
           0.05128205128205128,
           0.038461538461538464,
           0
          ],
          [
           0.010869565217391304,
           0,
           0,
           0.05434782608695652,
           0.043478260869565216,
           0.010869565217391304,
           0,
           0,
           0.021739130434782608,
           0,
           0.010869565217391304,
           0,
           0.043478260869565216,
           0.03260869565217391,
           0.010869565217391304,
           0.021739130434782608,
           0.03260869565217391,
           0.05434782608695652,
           0.010869565217391304,
           0.010869565217391304,
           0,
           0,
           0.010869565217391304,
           0.010869565217391304,
           0.021739130434782608,
           0,
           0.010869565217391304,
           0.021739130434782608,
           0,
           0,
           0.44565217391304346,
           0,
           0,
           0,
           0.010869565217391304,
           0.021739130434782608,
           0.03260869565217391,
           0,
           0.043478260869565216
          ],
          [
           0,
           0,
           0,
           0.05,
           0,
           0,
           0,
           0.05,
           0.05,
           0.05,
           0.05,
           0,
           0.05,
           0,
           0.05,
           0.1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1,
           0.05,
           0.05,
           0,
           0,
           0,
           0.05,
           0.05,
           0.15,
           0,
           0,
           0.1,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0.013888888888888888,
           0.027777777777777776,
           0,
           0.013888888888888888,
           0.013888888888888888,
           0,
           0,
           0,
           0.013888888888888888,
           0.05555555555555555,
           0.041666666666666664,
           0.027777777777777776,
           0.013888888888888888,
           0,
           0,
           0.125,
           0.041666666666666664,
           0,
           0,
           0.027777777777777776,
           0.013888888888888888,
           0.041666666666666664,
           0,
           0.041666666666666664,
           0.013888888888888888,
           0.013888888888888888,
           0,
           0.041666666666666664,
           0,
           0.013888888888888888,
           0,
           0.20833333333333334,
           0,
           0,
           0.08333333333333333,
           0.041666666666666664,
           0.013888888888888888,
           0.05555555555555555
          ],
          [
           0,
           0,
           0,
           0.01818181818181818,
           0,
           0.01818181818181818,
           0,
           0,
           0,
           0,
           0,
           0,
           0.01818181818181818,
           0.01818181818181818,
           0.01818181818181818,
           0.05454545454545454,
           0.01818181818181818,
           0.01818181818181818,
           0.01818181818181818,
           0,
           0,
           0.01818181818181818,
           0,
           0.01818181818181818,
           0.05454545454545454,
           0.01818181818181818,
           0.03636363636363636,
           0,
           0.03636363636363636,
           0.05454545454545454,
           0.10909090909090909,
           0,
           0.01818181818181818,
           0.32727272727272727,
           0,
           0.03636363636363636,
           0.03636363636363636,
           0.01818181818181818,
           0.01818181818181818
          ],
          [
           0.04,
           0.04,
           0,
           0.02,
           0.02,
           0.04,
           0,
           0,
           0.02,
           0.02,
           0.02,
           0.04,
           0.02,
           0,
           0,
           0,
           0,
           0.02,
           0.02,
           0,
           0.08,
           0.02,
           0.02,
           0,
           0,
           0,
           0,
           0.06,
           0,
           0.04,
           0.06,
           0,
           0,
           0,
           0.24,
           0,
           0.02,
           0.02,
           0.12
          ],
          [
           0.009433962264150943,
           0.018867924528301886,
           0.009433962264150943,
           0.009433962264150943,
           0,
           0.0660377358490566,
           0,
           0.018867924528301886,
           0,
           0,
           0.009433962264150943,
           0.009433962264150943,
           0.02830188679245283,
           0.02830188679245283,
           0.009433962264150943,
           0.018867924528301886,
           0.10377358490566038,
           0,
           0.04716981132075472,
           0.018867924528301886,
           0,
           0.018867924528301886,
           0.018867924528301886,
           0,
           0.018867924528301886,
           0.02830188679245283,
           0.02830188679245283,
           0.018867924528301886,
           0.018867924528301886,
           0,
           0.018867924528301886,
           0,
           0.03773584905660377,
           0.009433962264150943,
           0.018867924528301886,
           0.27358490566037735,
           0.05660377358490566,
           0.02830188679245283,
           0
          ],
          [
           0.012658227848101266,
           0.012658227848101266,
           0.02531645569620253,
           0.012658227848101266,
           0,
           0.05063291139240506,
           0,
           0,
           0,
           0.012658227848101266,
           0,
           0,
           0.012658227848101266,
           0.012658227848101266,
           0.012658227848101266,
           0,
           0.0759493670886076,
           0.02531645569620253,
           0.012658227848101266,
           0.012658227848101266,
           0.012658227848101266,
           0,
           0.012658227848101266,
           0.05063291139240506,
           0.012658227848101266,
           0.012658227848101266,
           0.0379746835443038,
           0.012658227848101266,
           0.012658227848101266,
           0.012658227848101266,
           0.012658227848101266,
           0,
           0,
           0,
           0,
           0.0379746835443038,
           0.4810126582278481,
           0,
           0
          ],
          [
           0.014285714285714285,
           0.014285714285714285,
           0,
           0.014285714285714285,
           0,
           0.02857142857142857,
           0.014285714285714285,
           0,
           0.014285714285714285,
           0.014285714285714285,
           0.04285714285714286,
           0,
           0.02857142857142857,
           0.07142857142857142,
           0,
           0,
           0.12857142857142856,
           0.014285714285714285,
           0.014285714285714285,
           0,
           0,
           0.014285714285714285,
           0,
           0,
           0,
           0.014285714285714285,
           0.04285714285714286,
           0,
           0.014285714285714285,
           0.014285714285714285,
           0.014285714285714285,
           0,
           0.014285714285714285,
           0.014285714285714285,
           0.014285714285714285,
           0.04285714285714286,
           0.07142857142857142,
           0.2714285714285714,
           0.04285714285714286
          ],
          [
           0.011111111111111112,
           0.03333333333333333,
           0.022222222222222223,
           0.06666666666666667,
           0.022222222222222223,
           0.011111111111111112,
           0,
           0,
           0.022222222222222223,
           0,
           0,
           0,
           0.022222222222222223,
           0.011111111111111112,
           0.022222222222222223,
           0,
           0.011111111111111112,
           0.022222222222222223,
           0.022222222222222223,
           0.022222222222222223,
           0.03333333333333333,
           0,
           0.03333333333333333,
           0.03333333333333333,
           0.03333333333333333,
           0.03333333333333333,
           0.044444444444444446,
           0.022222222222222223,
           0,
           0.011111111111111112,
           0.06666666666666667,
           0,
           0.011111111111111112,
           0,
           0,
           0.011111111111111112,
           0.022222222222222223,
           0.07777777777777778,
           0.24444444444444444
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Normalized Confusion"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Confusion Matrix Heatmap"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Predicted Labels"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "True Labels"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalized_confusion = confusion.astype('float') / confusion.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create a DataFrame for the heatmap\n",
    "df = pd.DataFrame(normalized_confusion, index=list(range(39)), columns=list(range(39)))\n",
    "df.to_csv('confusion_matrix_data.csv', index=False)\n",
    "\n",
    "# Create the heatmap using Plotly Express\n",
    "fig = px.imshow(df,\n",
    "                x=list(range(39)),\n",
    "                y=list(range(39)),\n",
    "                color_continuous_scale='Viridis',  # Choose your desired color scale\n",
    "                labels=dict(x='Predicted Labels', y='True Labels', color='Normalized Confusion')\n",
    "                )\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(title='Confusion Matrix Heatmap')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

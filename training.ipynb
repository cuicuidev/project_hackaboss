{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "GPU 1: PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for i, device in enumerate(physical_devices):\n",
    "    print(f\"GPU {i}: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'car_make_images/'\n",
    "training_path = path + 'train'\n",
    "testing_path = path + 'test'\n",
    "validation_path = path + 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_generator = ImageDataGenerator(rescale = 1./255,\n",
    "                              rotation_range = 359,\n",
    "                              shear_range = 0.2,\n",
    "                              width_shift_range = 0.2,\n",
    "                              height_shift_range = 0.2,\n",
    "                              zoom_range = 0.2,\n",
    "                              horizontal_flip = True,\n",
    "                              vertical_flip = True,\n",
    "                              preprocessing_function = None)\n",
    "\n",
    "validation_data_generator = ImageDataGenerator(rescale = 1./255)\n",
    "test_data_generator = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11573 images belonging to 39 classes.\n",
      "Found 2813 images belonging to 39 classes.\n",
      "Found 2871 images belonging to 39 classes.\n"
     ]
    }
   ],
   "source": [
    "size = 200\n",
    "batch_size = 30  \n",
    "num_classes = 39\n",
    "\n",
    "training_generator = training_data_generator.flow_from_directory(training_path,\n",
    "                                                                 target_size = (size, size),\n",
    "                                                                 batch_size = 30,\n",
    "                                                                 class_mode = \"categorical\",\n",
    "                                                                 color_mode = 'grayscale',\n",
    "                                                                 )\n",
    "\n",
    "validation_generator = validation_data_generator.flow_from_directory(validation_path,\n",
    "                                                                     target_size = (size, size),\n",
    "                                                                     batch_size = 1,\n",
    "                                                                     class_mode = \"categorical\",\n",
    "                                                                     color_mode = 'grayscale',\n",
    "                                                                     )\n",
    "\n",
    "test_generator = test_data_generator.flow_from_directory(testing_path,\n",
    "                                                         target_size = (size, size),\n",
    "                                                         batch_size = 1,\n",
    "                                                         class_mode = \"categorical\",\n",
    "                                                         color_mode = 'grayscale',\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/GPU:0\"):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(size, size, 1)))\n",
    "\n",
    "    # First Conv Block\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal'))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Second Conv Block\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal'))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Third Conv Block\n",
    "    model.add(Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal'))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Fourth Conv Block\n",
    "    model.add(Conv2D(filters=256, kernel_size=3, padding='same', kernel_initializer='he_normal'))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Flatten and Fully Connected Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_initializer='he_normal'))\n",
    "\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate=0.001,\n",
    "                decay_steps=10000,\n",
    "                decay_rate=0.9)\n",
    "    opt = Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(model, train_data, val_data, epochs, save_interval, model_save_path, history_save_path, custom_metrics=None, custom_optimizer=None):\n",
    "    \"\"\"\n",
    "    Train a TensorFlow model and save it along with its history.\n",
    "    \"\"\"\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "    if custom_optimizer:\n",
    "        optimizer = custom_optimizer\n",
    "    else:\n",
    "        optimizer = 'adam'\n",
    "\n",
    "    if custom_metrics:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'] + custom_metrics)\n",
    "    else:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    # Initialize variables\n",
    "    initial_epoch = 0\n",
    "    temp_history_data = []\n",
    "\n",
    "    # Check if history file exists, if not create it\n",
    "    if not os.path.exists(history_save_path):\n",
    "        with open(history_save_path, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            columns = ['Epoch', 'Loss', 'Accuracy', 'Val_Loss', 'Val_Accuracy']\n",
    "            if custom_metrics:\n",
    "                for metric in custom_metrics:\n",
    "                    metric_name = metric.__name__\n",
    "                    columns.append(metric_name)\n",
    "                    columns.append(\"Val_\" + metric_name)\n",
    "            csv_writer.writerow(columns)\n",
    "    else:\n",
    "        with open(history_save_path, 'r') as csvfile:\n",
    "            csv_reader = csv.reader(csvfile)\n",
    "            last_row = None\n",
    "            for row in csv_reader:\n",
    "                last_row = row\n",
    "            if last_row:\n",
    "                initial_epoch = int(last_row[0])\n",
    "\n",
    "    latest_model_file = max(glob.glob(f\"{model_save_path}/model_e*.h5\"), default=None, key=os.path.getctime)\n",
    "    if latest_model_file is not None:\n",
    "        print(f\"Resuming from {latest_model_file}\")\n",
    "        model = tf.keras.models.load_model(latest_model_file, custom_objects={metric.__name__: metric for metric in custom_metrics})\n",
    "\n",
    "    for epoch in range(initial_epoch + 1, epochs + initial_epoch + 1):\n",
    "        print(f\"Epoch {epoch}/{epochs + initial_epoch}\")\n",
    "\n",
    "        history = model.fit(train_data, validation_data=val_data)\n",
    "        history_data = [epoch] + [history.history[key][0] for key in history.history]\n",
    "        temp_history_data.append(history_data)\n",
    "\n",
    "        if epoch % save_interval == 0 or epoch == epochs + initial_epoch:\n",
    "            model_file_path = os.path.join(model_save_path, f\"model_e{epoch}.h5\")\n",
    "            model.save(model_file_path)\n",
    "\n",
    "            # Append to CSV at checkpoints\n",
    "            with open(history_save_path, 'a', newline='') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                for row in temp_history_data:\n",
    "                    csv_writer.writerow(row)\n",
    "\n",
    "            # Clear temporary history data\n",
    "            temp_history_data.clear()\n",
    "\n",
    "            print(f\"Saved model and history at epoch {epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    actual_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    \n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (actual_positives + K.epsilon())\n",
    "    \n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    return f1_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from models\\model_e240.h5\n",
      "Epoch 241/500\n",
      "386/386 [==============================] - 236s 610ms/step - loss: 1.9966 - accuracy: 0.4371 - f1_score: 0.3948 - val_loss: 3.3537 - val_accuracy: 0.2844 - val_f1_score: 0.2158\n",
      "Epoch 242/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.9810 - accuracy: 0.4414 - f1_score: 0.4070 - val_loss: 3.4148 - val_accuracy: 0.2826 - val_f1_score: 0.2062\n",
      "Epoch 243/500\n",
      "386/386 [==============================] - 91s 236ms/step - loss: 1.9841 - accuracy: 0.4383 - f1_score: 0.4001 - val_loss: 3.6252 - val_accuracy: 0.2730 - val_f1_score: 0.2048\n",
      "Epoch 244/500\n",
      "386/386 [==============================] - 90s 233ms/step - loss: 1.9932 - accuracy: 0.4383 - f1_score: 0.4090 - val_loss: 3.3868 - val_accuracy: 0.2901 - val_f1_score: 0.2101\n",
      "Epoch 245/500\n",
      "386/386 [==============================] - 91s 236ms/step - loss: 1.9758 - accuracy: 0.4426 - f1_score: 0.4000 - val_loss: 3.6209 - val_accuracy: 0.2727 - val_f1_score: 0.1994\n",
      "Epoch 246/500\n",
      "386/386 [==============================] - 91s 235ms/step - loss: 1.9631 - accuracy: 0.4442 - f1_score: 0.4074 - val_loss: 3.5445 - val_accuracy: 0.2734 - val_f1_score: 0.2005\n",
      "Epoch 247/500\n",
      "386/386 [==============================] - 91s 237ms/step - loss: 1.9701 - accuracy: 0.4410 - f1_score: 0.4069 - val_loss: 3.4786 - val_accuracy: 0.2769 - val_f1_score: 0.2033\n",
      "Epoch 248/500\n",
      "386/386 [==============================] - 91s 235ms/step - loss: 1.9696 - accuracy: 0.4396 - f1_score: 0.4099 - val_loss: 3.6855 - val_accuracy: 0.2677 - val_f1_score: 0.1980\n",
      "Epoch 249/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.9563 - accuracy: 0.4449 - f1_score: 0.4108 - val_loss: 3.3831 - val_accuracy: 0.2883 - val_f1_score: 0.2112\n",
      "Epoch 250/500\n",
      "386/386 [==============================] - 91s 235ms/step - loss: 1.9437 - accuracy: 0.4494 - f1_score: 0.4153 - val_loss: 3.4297 - val_accuracy: 0.2784 - val_f1_score: 0.2001\n",
      "Saved model and history at epoch 250\n",
      "Epoch 251/500\n",
      "386/386 [==============================] - 91s 235ms/step - loss: 1.9636 - accuracy: 0.4434 - f1_score: 0.4127 - val_loss: 3.2667 - val_accuracy: 0.2865 - val_f1_score: 0.2069\n",
      "Epoch 252/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.9655 - accuracy: 0.4419 - f1_score: 0.4064 - val_loss: 3.2897 - val_accuracy: 0.2940 - val_f1_score: 0.2204\n",
      "Epoch 253/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.9565 - accuracy: 0.4426 - f1_score: 0.4052 - val_loss: 3.5092 - val_accuracy: 0.2702 - val_f1_score: 0.1987\n",
      "Epoch 254/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.9534 - accuracy: 0.4465 - f1_score: 0.4122 - val_loss: 3.2637 - val_accuracy: 0.2897 - val_f1_score: 0.2115\n",
      "Epoch 255/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.9484 - accuracy: 0.4449 - f1_score: 0.4151 - val_loss: 3.3503 - val_accuracy: 0.2940 - val_f1_score: 0.2055\n",
      "Epoch 256/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.9297 - accuracy: 0.4510 - f1_score: 0.4162 - val_loss: 3.3607 - val_accuracy: 0.2819 - val_f1_score: 0.2048\n",
      "Epoch 257/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.9522 - accuracy: 0.4409 - f1_score: 0.4104 - val_loss: 3.3329 - val_accuracy: 0.2812 - val_f1_score: 0.1969\n",
      "Epoch 258/500\n",
      "386/386 [==============================] - 90s 234ms/step - loss: 1.9485 - accuracy: 0.4520 - f1_score: 0.4164 - val_loss: 3.5651 - val_accuracy: 0.2791 - val_f1_score: 0.2058\n",
      "Epoch 259/500\n",
      "386/386 [==============================] - 88s 228ms/step - loss: 1.9268 - accuracy: 0.4524 - f1_score: 0.4191 - val_loss: 3.4445 - val_accuracy: 0.2858 - val_f1_score: 0.2105\n",
      "Epoch 260/500\n",
      "386/386 [==============================] - 89s 231ms/step - loss: 1.9093 - accuracy: 0.4552 - f1_score: 0.4205 - val_loss: 3.3476 - val_accuracy: 0.2872 - val_f1_score: 0.2083\n",
      "Saved model and history at epoch 260\n",
      "Epoch 261/500\n",
      "386/386 [==============================] - 91s 235ms/step - loss: 1.9257 - accuracy: 0.4536 - f1_score: 0.4200 - val_loss: 3.3183 - val_accuracy: 0.2908 - val_f1_score: 0.2048\n",
      "Epoch 262/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.9159 - accuracy: 0.4541 - f1_score: 0.4204 - val_loss: 3.3677 - val_accuracy: 0.2748 - val_f1_score: 0.1977\n",
      "Epoch 263/500\n",
      "386/386 [==============================] - 91s 236ms/step - loss: 1.9040 - accuracy: 0.4570 - f1_score: 0.4326 - val_loss: 3.2774 - val_accuracy: 0.2936 - val_f1_score: 0.2158\n",
      "Epoch 264/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.9084 - accuracy: 0.4640 - f1_score: 0.4306 - val_loss: 3.3774 - val_accuracy: 0.2812 - val_f1_score: 0.2005\n",
      "Epoch 265/500\n",
      "386/386 [==============================] - 91s 237ms/step - loss: 1.9045 - accuracy: 0.4589 - f1_score: 0.4273 - val_loss: 3.4218 - val_accuracy: 0.2833 - val_f1_score: 0.2097\n",
      "Epoch 266/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.8979 - accuracy: 0.4646 - f1_score: 0.4387 - val_loss: 3.2641 - val_accuracy: 0.2940 - val_f1_score: 0.2122\n",
      "Epoch 267/500\n",
      "386/386 [==============================] - 91s 235ms/step - loss: 1.8891 - accuracy: 0.4652 - f1_score: 0.4322 - val_loss: 3.4111 - val_accuracy: 0.2879 - val_f1_score: 0.2097\n",
      "Epoch 268/500\n",
      "386/386 [==============================] - 89s 230ms/step - loss: 1.9088 - accuracy: 0.4601 - f1_score: 0.4293 - val_loss: 3.3100 - val_accuracy: 0.2908 - val_f1_score: 0.2147\n",
      "Epoch 269/500\n",
      "386/386 [==============================] - 89s 231ms/step - loss: 1.9047 - accuracy: 0.4584 - f1_score: 0.4255 - val_loss: 3.3974 - val_accuracy: 0.2947 - val_f1_score: 0.2080\n",
      "Epoch 270/500\n",
      "386/386 [==============================] - 88s 229ms/step - loss: 1.8889 - accuracy: 0.4633 - f1_score: 0.4331 - val_loss: 3.5195 - val_accuracy: 0.2897 - val_f1_score: 0.2140\n",
      "Saved model and history at epoch 270\n",
      "Epoch 271/500\n",
      "386/386 [==============================] - 91s 236ms/step - loss: 1.8853 - accuracy: 0.4643 - f1_score: 0.4348 - val_loss: 3.4472 - val_accuracy: 0.2901 - val_f1_score: 0.2090\n",
      "Epoch 272/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.8787 - accuracy: 0.4682 - f1_score: 0.4362 - val_loss: 3.3563 - val_accuracy: 0.3015 - val_f1_score: 0.2112\n",
      "Epoch 273/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.8845 - accuracy: 0.4570 - f1_score: 0.4285 - val_loss: 3.2616 - val_accuracy: 0.3022 - val_f1_score: 0.2222\n",
      "Epoch 274/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.8808 - accuracy: 0.4663 - f1_score: 0.4372 - val_loss: 3.5164 - val_accuracy: 0.2958 - val_f1_score: 0.2133\n",
      "Epoch 275/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.8577 - accuracy: 0.4714 - f1_score: 0.4443 - val_loss: 3.4192 - val_accuracy: 0.3032 - val_f1_score: 0.2264\n",
      "Epoch 276/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.8705 - accuracy: 0.4657 - f1_score: 0.4416 - val_loss: 3.4492 - val_accuracy: 0.3064 - val_f1_score: 0.2296\n",
      "Epoch 277/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.8654 - accuracy: 0.4730 - f1_score: 0.4402 - val_loss: 3.3192 - val_accuracy: 0.3036 - val_f1_score: 0.2218\n",
      "Epoch 278/500\n",
      "386/386 [==============================] - 88s 229ms/step - loss: 1.8580 - accuracy: 0.4746 - f1_score: 0.4373 - val_loss: 3.1728 - val_accuracy: 0.3086 - val_f1_score: 0.2215\n",
      "Epoch 279/500\n",
      "386/386 [==============================] - 89s 230ms/step - loss: 1.8448 - accuracy: 0.4736 - f1_score: 0.4478 - val_loss: 3.3687 - val_accuracy: 0.2940 - val_f1_score: 0.2232\n",
      "Epoch 280/500\n",
      "386/386 [==============================] - 89s 230ms/step - loss: 1.8546 - accuracy: 0.4728 - f1_score: 0.4415 - val_loss: 3.4055 - val_accuracy: 0.2983 - val_f1_score: 0.2236\n",
      "Saved model and history at epoch 280\n",
      "Epoch 281/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.8357 - accuracy: 0.4773 - f1_score: 0.4485 - val_loss: 3.3750 - val_accuracy: 0.2936 - val_f1_score: 0.2204\n",
      "Epoch 282/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.8613 - accuracy: 0.4786 - f1_score: 0.4448 - val_loss: 3.5147 - val_accuracy: 0.2855 - val_f1_score: 0.2158\n",
      "Epoch 283/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.8539 - accuracy: 0.4669 - f1_score: 0.4429 - val_loss: 3.3019 - val_accuracy: 0.3011 - val_f1_score: 0.2186\n",
      "Epoch 284/500\n",
      "386/386 [==============================] - 91s 237ms/step - loss: 1.8340 - accuracy: 0.4777 - f1_score: 0.4533 - val_loss: 3.4277 - val_accuracy: 0.2975 - val_f1_score: 0.2176\n",
      "Epoch 285/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.8406 - accuracy: 0.4761 - f1_score: 0.4473 - val_loss: 3.2689 - val_accuracy: 0.3047 - val_f1_score: 0.2218\n",
      "Epoch 286/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.8323 - accuracy: 0.4798 - f1_score: 0.4520 - val_loss: 3.6273 - val_accuracy: 0.2943 - val_f1_score: 0.2208\n",
      "Epoch 287/500\n",
      "386/386 [==============================] - 91s 236ms/step - loss: 1.8206 - accuracy: 0.4815 - f1_score: 0.4519 - val_loss: 3.5361 - val_accuracy: 0.2972 - val_f1_score: 0.2232\n",
      "Epoch 288/500\n",
      "386/386 [==============================] - 89s 231ms/step - loss: 1.8234 - accuracy: 0.4816 - f1_score: 0.4537 - val_loss: 3.6162 - val_accuracy: 0.2887 - val_f1_score: 0.2151\n",
      "Epoch 289/500\n",
      "386/386 [==============================] - 88s 229ms/step - loss: 1.8210 - accuracy: 0.4803 - f1_score: 0.4522 - val_loss: 3.4962 - val_accuracy: 0.2975 - val_f1_score: 0.2222\n",
      "Epoch 290/500\n",
      "386/386 [==============================] - 89s 231ms/step - loss: 1.8341 - accuracy: 0.4808 - f1_score: 0.4512 - val_loss: 3.4488 - val_accuracy: 0.2947 - val_f1_score: 0.2272\n",
      "Saved model and history at epoch 290\n",
      "Epoch 291/500\n",
      "386/386 [==============================] - 90s 234ms/step - loss: 1.8209 - accuracy: 0.4835 - f1_score: 0.4523 - val_loss: 3.3782 - val_accuracy: 0.2983 - val_f1_score: 0.2197\n",
      "Epoch 292/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.8093 - accuracy: 0.4843 - f1_score: 0.4592 - val_loss: 3.3713 - val_accuracy: 0.3057 - val_f1_score: 0.2261\n",
      "Epoch 293/500\n",
      "386/386 [==============================] - 91s 236ms/step - loss: 1.8198 - accuracy: 0.4794 - f1_score: 0.4519 - val_loss: 3.3118 - val_accuracy: 0.3061 - val_f1_score: 0.2296\n",
      "Epoch 294/500\n",
      "386/386 [==============================] - 91s 237ms/step - loss: 1.8166 - accuracy: 0.4831 - f1_score: 0.4572 - val_loss: 3.4302 - val_accuracy: 0.3061 - val_f1_score: 0.2247\n",
      "Epoch 295/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.8079 - accuracy: 0.4834 - f1_score: 0.4576 - val_loss: 3.5585 - val_accuracy: 0.2968 - val_f1_score: 0.2186\n",
      "Epoch 296/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.7841 - accuracy: 0.4924 - f1_score: 0.4660 - val_loss: 3.4766 - val_accuracy: 0.2972 - val_f1_score: 0.2211\n",
      "Epoch 297/500\n",
      "386/386 [==============================] - 91s 236ms/step - loss: 1.8037 - accuracy: 0.4896 - f1_score: 0.4613 - val_loss: 3.5884 - val_accuracy: 0.2908 - val_f1_score: 0.2222\n",
      "Epoch 298/500\n",
      "386/386 [==============================] - 89s 230ms/step - loss: 1.8041 - accuracy: 0.4889 - f1_score: 0.4637 - val_loss: 3.3311 - val_accuracy: 0.3199 - val_f1_score: 0.2339\n",
      "Epoch 299/500\n",
      "386/386 [==============================] - 88s 229ms/step - loss: 1.8001 - accuracy: 0.4856 - f1_score: 0.4588 - val_loss: 3.4812 - val_accuracy: 0.3079 - val_f1_score: 0.2382\n",
      "Epoch 300/500\n",
      "386/386 [==============================] - 89s 229ms/step - loss: 1.7761 - accuracy: 0.4917 - f1_score: 0.4669 - val_loss: 3.6946 - val_accuracy: 0.2798 - val_f1_score: 0.2147\n",
      "Saved model and history at epoch 300\n",
      "Epoch 301/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.7892 - accuracy: 0.4871 - f1_score: 0.4612 - val_loss: 3.1841 - val_accuracy: 0.3189 - val_f1_score: 0.2328\n",
      "Epoch 302/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.7927 - accuracy: 0.4858 - f1_score: 0.4646 - val_loss: 3.4284 - val_accuracy: 0.3121 - val_f1_score: 0.2311\n",
      "Epoch 303/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.7995 - accuracy: 0.4854 - f1_score: 0.4595 - val_loss: 3.5641 - val_accuracy: 0.2951 - val_f1_score: 0.2261\n",
      "Epoch 304/500\n",
      "386/386 [==============================] - 91s 237ms/step - loss: 1.7757 - accuracy: 0.4917 - f1_score: 0.4634 - val_loss: 3.3564 - val_accuracy: 0.3121 - val_f1_score: 0.2368\n",
      "Epoch 305/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.7801 - accuracy: 0.4883 - f1_score: 0.4627 - val_loss: 3.4810 - val_accuracy: 0.3132 - val_f1_score: 0.2346\n",
      "Epoch 306/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.7733 - accuracy: 0.4906 - f1_score: 0.4712 - val_loss: 3.3532 - val_accuracy: 0.3107 - val_f1_score: 0.2318\n",
      "Epoch 307/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.7543 - accuracy: 0.4949 - f1_score: 0.4717 - val_loss: 3.5476 - val_accuracy: 0.3007 - val_f1_score: 0.2293\n",
      "Epoch 308/500\n",
      "386/386 [==============================] - 94s 242ms/step - loss: 1.7903 - accuracy: 0.4862 - f1_score: 0.4688 - val_loss: 3.8268 - val_accuracy: 0.2919 - val_f1_score: 0.2272\n",
      "Epoch 309/500\n",
      "386/386 [==============================] - 214s 553ms/step - loss: 1.7724 - accuracy: 0.4965 - f1_score: 0.4659 - val_loss: 3.3315 - val_accuracy: 0.3160 - val_f1_score: 0.2364\n",
      "Epoch 310/500\n",
      "386/386 [==============================] - 88s 229ms/step - loss: 1.7598 - accuracy: 0.4949 - f1_score: 0.4710 - val_loss: 3.6627 - val_accuracy: 0.2911 - val_f1_score: 0.2282\n",
      "Saved model and history at epoch 310\n",
      "Epoch 311/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.7605 - accuracy: 0.4956 - f1_score: 0.4782 - val_loss: 3.4109 - val_accuracy: 0.3057 - val_f1_score: 0.2360\n",
      "Epoch 312/500\n",
      "386/386 [==============================] - 93s 239ms/step - loss: 1.7622 - accuracy: 0.4956 - f1_score: 0.4726 - val_loss: 3.5567 - val_accuracy: 0.3018 - val_f1_score: 0.2264\n",
      "Epoch 313/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.7499 - accuracy: 0.5012 - f1_score: 0.4783 - val_loss: 3.5561 - val_accuracy: 0.3054 - val_f1_score: 0.2332\n",
      "Epoch 314/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.7611 - accuracy: 0.4989 - f1_score: 0.4734 - val_loss: 3.6260 - val_accuracy: 0.3000 - val_f1_score: 0.2293\n",
      "Epoch 315/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.7476 - accuracy: 0.5054 - f1_score: 0.4812 - val_loss: 3.6744 - val_accuracy: 0.2954 - val_f1_score: 0.2236\n",
      "Epoch 316/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.7435 - accuracy: 0.5051 - f1_score: 0.4771 - val_loss: 3.4814 - val_accuracy: 0.3128 - val_f1_score: 0.2403\n",
      "Epoch 317/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.7341 - accuracy: 0.5042 - f1_score: 0.4832 - val_loss: 3.4265 - val_accuracy: 0.3171 - val_f1_score: 0.2424\n",
      "Epoch 318/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.7373 - accuracy: 0.4994 - f1_score: 0.4808 - val_loss: 3.4308 - val_accuracy: 0.3143 - val_f1_score: 0.2353\n",
      "Epoch 319/500\n",
      "386/386 [==============================] - 91s 237ms/step - loss: 1.7336 - accuracy: 0.4997 - f1_score: 0.4759 - val_loss: 3.5201 - val_accuracy: 0.2968 - val_f1_score: 0.2254\n",
      "Epoch 320/500\n",
      "386/386 [==============================] - 93s 242ms/step - loss: 1.7481 - accuracy: 0.4987 - f1_score: 0.4779 - val_loss: 3.6458 - val_accuracy: 0.3011 - val_f1_score: 0.2378\n",
      "Saved model and history at epoch 320\n",
      "Epoch 321/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.7438 - accuracy: 0.5025 - f1_score: 0.4827 - val_loss: 3.3428 - val_accuracy: 0.3075 - val_f1_score: 0.2350\n",
      "Epoch 322/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.7278 - accuracy: 0.5020 - f1_score: 0.4787 - val_loss: 3.4725 - val_accuracy: 0.3128 - val_f1_score: 0.2392\n",
      "Epoch 323/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.7358 - accuracy: 0.5070 - f1_score: 0.4842 - val_loss: 3.5852 - val_accuracy: 0.3139 - val_f1_score: 0.2442\n",
      "Epoch 324/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.7187 - accuracy: 0.5032 - f1_score: 0.4864 - val_loss: 3.6798 - val_accuracy: 0.3025 - val_f1_score: 0.2407\n",
      "Epoch 325/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.7230 - accuracy: 0.5101 - f1_score: 0.4871 - val_loss: 3.4387 - val_accuracy: 0.3150 - val_f1_score: 0.2460\n",
      "Epoch 326/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6916 - accuracy: 0.5231 - f1_score: 0.4962 - val_loss: 3.7417 - val_accuracy: 0.2997 - val_f1_score: 0.2364\n",
      "Epoch 327/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.7152 - accuracy: 0.5045 - f1_score: 0.4874 - val_loss: 3.5819 - val_accuracy: 0.3015 - val_f1_score: 0.2375\n",
      "Epoch 328/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6994 - accuracy: 0.5114 - f1_score: 0.4929 - val_loss: 3.3580 - val_accuracy: 0.3217 - val_f1_score: 0.2528\n",
      "Epoch 329/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.7019 - accuracy: 0.5133 - f1_score: 0.4907 - val_loss: 3.4588 - val_accuracy: 0.3143 - val_f1_score: 0.2428\n",
      "Epoch 330/500\n",
      "386/386 [==============================] - 91s 236ms/step - loss: 1.7168 - accuracy: 0.5050 - f1_score: 0.4868 - val_loss: 3.4659 - val_accuracy: 0.3118 - val_f1_score: 0.2453\n",
      "Saved model and history at epoch 330\n",
      "Epoch 331/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6811 - accuracy: 0.5149 - f1_score: 0.4922 - val_loss: 3.4399 - val_accuracy: 0.3178 - val_f1_score: 0.2478\n",
      "Epoch 332/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.6865 - accuracy: 0.5114 - f1_score: 0.4890 - val_loss: 3.7139 - val_accuracy: 0.3007 - val_f1_score: 0.2467\n",
      "Epoch 333/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.6799 - accuracy: 0.5190 - f1_score: 0.5046 - val_loss: 3.7774 - val_accuracy: 0.3004 - val_f1_score: 0.2396\n",
      "Epoch 334/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6755 - accuracy: 0.5169 - f1_score: 0.5010 - val_loss: 3.7100 - val_accuracy: 0.3089 - val_f1_score: 0.2496\n",
      "Epoch 335/500\n",
      "386/386 [==============================] - 92s 240ms/step - loss: 1.6706 - accuracy: 0.5165 - f1_score: 0.5102 - val_loss: 3.5489 - val_accuracy: 0.3121 - val_f1_score: 0.2499\n",
      "Epoch 336/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.7066 - accuracy: 0.5084 - f1_score: 0.4915 - val_loss: 3.5338 - val_accuracy: 0.3125 - val_f1_score: 0.2488\n",
      "Epoch 337/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6843 - accuracy: 0.5174 - f1_score: 0.4978 - val_loss: 3.7147 - val_accuracy: 0.2972 - val_f1_score: 0.2407\n",
      "Epoch 338/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6737 - accuracy: 0.5233 - f1_score: 0.5009 - val_loss: 3.4498 - val_accuracy: 0.3171 - val_f1_score: 0.2474\n",
      "Epoch 339/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.6726 - accuracy: 0.5252 - f1_score: 0.5036 - val_loss: 3.3893 - val_accuracy: 0.3203 - val_f1_score: 0.2510\n",
      "Epoch 340/500\n",
      "386/386 [==============================] - 91s 235ms/step - loss: 1.6841 - accuracy: 0.5165 - f1_score: 0.4948 - val_loss: 3.4859 - val_accuracy: 0.3171 - val_f1_score: 0.2499\n",
      "Saved model and history at epoch 340\n",
      "Epoch 341/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6771 - accuracy: 0.5168 - f1_score: 0.5000 - val_loss: 3.3790 - val_accuracy: 0.3246 - val_f1_score: 0.2552\n",
      "Epoch 342/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.6719 - accuracy: 0.5188 - f1_score: 0.4985 - val_loss: 3.5968 - val_accuracy: 0.3050 - val_f1_score: 0.2389\n",
      "Epoch 343/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.6637 - accuracy: 0.5259 - f1_score: 0.5048 - val_loss: 3.5818 - val_accuracy: 0.3171 - val_f1_score: 0.2528\n",
      "Epoch 344/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.6582 - accuracy: 0.5242 - f1_score: 0.5024 - val_loss: 3.5009 - val_accuracy: 0.3178 - val_f1_score: 0.2499\n",
      "Epoch 345/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.6725 - accuracy: 0.5197 - f1_score: 0.5033 - val_loss: 3.4794 - val_accuracy: 0.3207 - val_f1_score: 0.2535\n",
      "Epoch 346/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.6607 - accuracy: 0.5187 - f1_score: 0.5057 - val_loss: 3.6081 - val_accuracy: 0.3118 - val_f1_score: 0.2517\n",
      "Epoch 347/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6622 - accuracy: 0.5242 - f1_score: 0.5033 - val_loss: 3.4539 - val_accuracy: 0.3214 - val_f1_score: 0.2542\n",
      "Epoch 348/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.6555 - accuracy: 0.5299 - f1_score: 0.5128 - val_loss: 3.5651 - val_accuracy: 0.3246 - val_f1_score: 0.2517\n",
      "Epoch 349/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.6574 - accuracy: 0.5235 - f1_score: 0.5072 - val_loss: 3.6200 - val_accuracy: 0.3064 - val_f1_score: 0.2375\n",
      "Epoch 350/500\n",
      "386/386 [==============================] - 91s 236ms/step - loss: 1.6454 - accuracy: 0.5290 - f1_score: 0.5077 - val_loss: 3.4835 - val_accuracy: 0.3182 - val_f1_score: 0.2517\n",
      "Saved model and history at epoch 350\n",
      "Epoch 351/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6568 - accuracy: 0.5261 - f1_score: 0.5114 - val_loss: 3.9827 - val_accuracy: 0.3004 - val_f1_score: 0.2385\n",
      "Epoch 352/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.6401 - accuracy: 0.5280 - f1_score: 0.5047 - val_loss: 3.7841 - val_accuracy: 0.3039 - val_f1_score: 0.2417\n",
      "Epoch 353/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.6416 - accuracy: 0.5231 - f1_score: 0.5103 - val_loss: 3.7855 - val_accuracy: 0.3050 - val_f1_score: 0.2428\n",
      "Epoch 354/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.6435 - accuracy: 0.5286 - f1_score: 0.5023 - val_loss: 3.7548 - val_accuracy: 0.2943 - val_f1_score: 0.2350\n",
      "Epoch 355/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.6390 - accuracy: 0.5317 - f1_score: 0.5113 - val_loss: 3.6377 - val_accuracy: 0.3057 - val_f1_score: 0.2471\n",
      "Epoch 356/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.6452 - accuracy: 0.5278 - f1_score: 0.5109 - val_loss: 3.6456 - val_accuracy: 0.3064 - val_f1_score: 0.2460\n",
      "Epoch 357/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.6236 - accuracy: 0.5324 - f1_score: 0.5127 - val_loss: 3.8292 - val_accuracy: 0.3022 - val_f1_score: 0.2467\n",
      "Epoch 358/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6315 - accuracy: 0.5324 - f1_score: 0.5182 - val_loss: 3.4816 - val_accuracy: 0.3263 - val_f1_score: 0.2584\n",
      "Epoch 359/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.6187 - accuracy: 0.5323 - f1_score: 0.5146 - val_loss: 3.5899 - val_accuracy: 0.3196 - val_f1_score: 0.2517\n",
      "Epoch 360/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6202 - accuracy: 0.5349 - f1_score: 0.5184 - val_loss: 3.6226 - val_accuracy: 0.3039 - val_f1_score: 0.2464\n",
      "Saved model and history at epoch 360\n",
      "Epoch 361/500\n",
      "386/386 [==============================] - 93s 239ms/step - loss: 1.6396 - accuracy: 0.5266 - f1_score: 0.5097 - val_loss: 3.6246 - val_accuracy: 0.3057 - val_f1_score: 0.2485\n",
      "Epoch 362/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6127 - accuracy: 0.5367 - f1_score: 0.5229 - val_loss: 3.7626 - val_accuracy: 0.3057 - val_f1_score: 0.2432\n",
      "Epoch 363/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.5996 - accuracy: 0.5356 - f1_score: 0.5205 - val_loss: 3.6592 - val_accuracy: 0.3057 - val_f1_score: 0.2464\n",
      "Epoch 364/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6184 - accuracy: 0.5312 - f1_score: 0.5201 - val_loss: 3.6333 - val_accuracy: 0.3118 - val_f1_score: 0.2510\n",
      "Epoch 365/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.6035 - accuracy: 0.5406 - f1_score: 0.5288 - val_loss: 3.6270 - val_accuracy: 0.3071 - val_f1_score: 0.2485\n",
      "Epoch 366/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6152 - accuracy: 0.5322 - f1_score: 0.5174 - val_loss: 3.7269 - val_accuracy: 0.3039 - val_f1_score: 0.2485\n",
      "Epoch 367/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.6273 - accuracy: 0.5312 - f1_score: 0.5179 - val_loss: 3.6531 - val_accuracy: 0.3025 - val_f1_score: 0.2449\n",
      "Epoch 368/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.5985 - accuracy: 0.5376 - f1_score: 0.5247 - val_loss: 3.7197 - val_accuracy: 0.3061 - val_f1_score: 0.2478\n",
      "Epoch 369/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5909 - accuracy: 0.5471 - f1_score: 0.5261 - val_loss: 3.6388 - val_accuracy: 0.3079 - val_f1_score: 0.2460\n",
      "Epoch 370/500\n",
      "386/386 [==============================] - 91s 235ms/step - loss: 1.5797 - accuracy: 0.5401 - f1_score: 0.5280 - val_loss: 3.5916 - val_accuracy: 0.3164 - val_f1_score: 0.2499\n",
      "Saved model and history at epoch 370\n",
      "Epoch 371/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.5972 - accuracy: 0.5452 - f1_score: 0.5209 - val_loss: 3.7189 - val_accuracy: 0.3004 - val_f1_score: 0.2371\n",
      "Epoch 372/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.6000 - accuracy: 0.5354 - f1_score: 0.5248 - val_loss: 3.6152 - val_accuracy: 0.3111 - val_f1_score: 0.2556\n",
      "Epoch 373/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.5978 - accuracy: 0.5433 - f1_score: 0.5238 - val_loss: 3.7552 - val_accuracy: 0.3011 - val_f1_score: 0.2421\n",
      "Epoch 374/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.5816 - accuracy: 0.5447 - f1_score: 0.5251 - val_loss: 3.7491 - val_accuracy: 0.3057 - val_f1_score: 0.2488\n",
      "Epoch 375/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.6085 - accuracy: 0.5407 - f1_score: 0.5257 - val_loss: 3.5552 - val_accuracy: 0.3096 - val_f1_score: 0.2481\n",
      "Epoch 376/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.5903 - accuracy: 0.5436 - f1_score: 0.5253 - val_loss: 3.6514 - val_accuracy: 0.3125 - val_f1_score: 0.2499\n",
      "Epoch 377/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5874 - accuracy: 0.5380 - f1_score: 0.5243 - val_loss: 3.7120 - val_accuracy: 0.3103 - val_f1_score: 0.2524\n",
      "Epoch 378/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.6008 - accuracy: 0.5362 - f1_score: 0.5273 - val_loss: 3.4518 - val_accuracy: 0.3196 - val_f1_score: 0.2510\n",
      "Epoch 379/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.5602 - accuracy: 0.5518 - f1_score: 0.5331 - val_loss: 3.4804 - val_accuracy: 0.3271 - val_f1_score: 0.2545\n",
      "Epoch 380/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.5661 - accuracy: 0.5473 - f1_score: 0.5321 - val_loss: 3.7506 - val_accuracy: 0.3004 - val_f1_score: 0.2471\n",
      "Saved model and history at epoch 380\n",
      "Epoch 381/500\n",
      "386/386 [==============================] - 91s 237ms/step - loss: 1.5546 - accuracy: 0.5517 - f1_score: 0.5309 - val_loss: 3.6401 - val_accuracy: 0.3111 - val_f1_score: 0.2481\n",
      "Epoch 382/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.5757 - accuracy: 0.5420 - f1_score: 0.5275 - val_loss: 3.4671 - val_accuracy: 0.3146 - val_f1_score: 0.2545\n",
      "Epoch 383/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.5682 - accuracy: 0.5477 - f1_score: 0.5324 - val_loss: 3.6451 - val_accuracy: 0.3061 - val_f1_score: 0.2488\n",
      "Epoch 384/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5711 - accuracy: 0.5467 - f1_score: 0.5336 - val_loss: 3.6675 - val_accuracy: 0.3068 - val_f1_score: 0.2496\n",
      "Epoch 385/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5492 - accuracy: 0.5525 - f1_score: 0.5376 - val_loss: 3.5792 - val_accuracy: 0.3153 - val_f1_score: 0.2588\n",
      "Epoch 386/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.5614 - accuracy: 0.5468 - f1_score: 0.5321 - val_loss: 3.7587 - val_accuracy: 0.3029 - val_f1_score: 0.2471\n",
      "Epoch 387/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5730 - accuracy: 0.5443 - f1_score: 0.5289 - val_loss: 3.6978 - val_accuracy: 0.3121 - val_f1_score: 0.2510\n",
      "Epoch 388/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5475 - accuracy: 0.5534 - f1_score: 0.5380 - val_loss: 3.6635 - val_accuracy: 0.3103 - val_f1_score: 0.2520\n",
      "Epoch 389/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.5694 - accuracy: 0.5446 - f1_score: 0.5330 - val_loss: 3.5577 - val_accuracy: 0.3178 - val_f1_score: 0.2560\n",
      "Epoch 390/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.5259 - accuracy: 0.5611 - f1_score: 0.5500 - val_loss: 3.5765 - val_accuracy: 0.3224 - val_f1_score: 0.2538\n",
      "Saved model and history at epoch 390\n",
      "Epoch 391/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5391 - accuracy: 0.5561 - f1_score: 0.5429 - val_loss: 3.8367 - val_accuracy: 0.2951 - val_f1_score: 0.2467\n",
      "Epoch 392/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5359 - accuracy: 0.5559 - f1_score: 0.5417 - val_loss: 3.6293 - val_accuracy: 0.3093 - val_f1_score: 0.2499\n",
      "Epoch 393/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.5707 - accuracy: 0.5486 - f1_score: 0.5386 - val_loss: 3.8260 - val_accuracy: 0.2936 - val_f1_score: 0.2421\n",
      "Epoch 394/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5369 - accuracy: 0.5550 - f1_score: 0.5450 - val_loss: 3.5039 - val_accuracy: 0.3192 - val_f1_score: 0.2570\n",
      "Epoch 395/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.5531 - accuracy: 0.5514 - f1_score: 0.5407 - val_loss: 3.6969 - val_accuracy: 0.3199 - val_f1_score: 0.2609\n",
      "Epoch 396/500\n",
      "386/386 [==============================] - 93s 242ms/step - loss: 1.5454 - accuracy: 0.5569 - f1_score: 0.5458 - val_loss: 3.6324 - val_accuracy: 0.3231 - val_f1_score: 0.2584\n",
      "Epoch 397/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.5362 - accuracy: 0.5566 - f1_score: 0.5423 - val_loss: 3.7073 - val_accuracy: 0.3153 - val_f1_score: 0.2528\n",
      "Epoch 398/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5488 - accuracy: 0.5504 - f1_score: 0.5366 - val_loss: 3.9879 - val_accuracy: 0.3079 - val_f1_score: 0.2524\n",
      "Epoch 399/500\n",
      "386/386 [==============================] - 93s 242ms/step - loss: 1.5374 - accuracy: 0.5580 - f1_score: 0.5461 - val_loss: 3.7108 - val_accuracy: 0.3214 - val_f1_score: 0.2702\n",
      "Epoch 400/500\n",
      "386/386 [==============================] - 93s 242ms/step - loss: 1.5358 - accuracy: 0.5522 - f1_score: 0.5403 - val_loss: 3.8189 - val_accuracy: 0.3100 - val_f1_score: 0.2471\n",
      "Saved model and history at epoch 400\n",
      "Epoch 401/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.5257 - accuracy: 0.5604 - f1_score: 0.5517 - val_loss: 3.6379 - val_accuracy: 0.3228 - val_f1_score: 0.2567\n",
      "Epoch 402/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.5439 - accuracy: 0.5562 - f1_score: 0.5400 - val_loss: 3.6967 - val_accuracy: 0.3121 - val_f1_score: 0.2520\n",
      "Epoch 403/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5208 - accuracy: 0.5589 - f1_score: 0.5448 - val_loss: 3.7539 - val_accuracy: 0.3135 - val_f1_score: 0.2556\n",
      "Epoch 404/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5129 - accuracy: 0.5604 - f1_score: 0.5523 - val_loss: 3.7023 - val_accuracy: 0.3121 - val_f1_score: 0.2528\n",
      "Epoch 405/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5255 - accuracy: 0.5598 - f1_score: 0.5502 - val_loss: 3.5672 - val_accuracy: 0.3199 - val_f1_score: 0.2609\n",
      "Epoch 406/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.5165 - accuracy: 0.5604 - f1_score: 0.5456 - val_loss: 3.5024 - val_accuracy: 0.3231 - val_f1_score: 0.2616\n",
      "Epoch 407/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5057 - accuracy: 0.5657 - f1_score: 0.5546 - val_loss: 3.5796 - val_accuracy: 0.3249 - val_f1_score: 0.2663\n",
      "Epoch 408/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.5221 - accuracy: 0.5627 - f1_score: 0.5500 - val_loss: 3.7839 - val_accuracy: 0.3146 - val_f1_score: 0.2588\n",
      "Epoch 409/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.4999 - accuracy: 0.5659 - f1_score: 0.5516 - val_loss: 3.5901 - val_accuracy: 0.3224 - val_f1_score: 0.2631\n",
      "Epoch 410/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.5004 - accuracy: 0.5659 - f1_score: 0.5496 - val_loss: 3.7349 - val_accuracy: 0.3171 - val_f1_score: 0.2588\n",
      "Saved model and history at epoch 410\n",
      "Epoch 411/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.5079 - accuracy: 0.5613 - f1_score: 0.5458 - val_loss: 3.6519 - val_accuracy: 0.3189 - val_f1_score: 0.2631\n",
      "Epoch 412/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.5057 - accuracy: 0.5642 - f1_score: 0.5509 - val_loss: 3.8660 - val_accuracy: 0.3079 - val_f1_score: 0.2552\n",
      "Epoch 413/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4988 - accuracy: 0.5683 - f1_score: 0.5553 - val_loss: 3.8172 - val_accuracy: 0.3029 - val_f1_score: 0.2538\n",
      "Epoch 414/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.5112 - accuracy: 0.5648 - f1_score: 0.5518 - val_loss: 3.7562 - val_accuracy: 0.3089 - val_f1_score: 0.2570\n",
      "Epoch 415/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.5042 - accuracy: 0.5624 - f1_score: 0.5559 - val_loss: 3.6421 - val_accuracy: 0.3224 - val_f1_score: 0.2624\n",
      "Epoch 416/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4945 - accuracy: 0.5641 - f1_score: 0.5558 - val_loss: 3.6979 - val_accuracy: 0.3118 - val_f1_score: 0.2599\n",
      "Epoch 417/500\n",
      "386/386 [==============================] - 93s 242ms/step - loss: 1.5203 - accuracy: 0.5616 - f1_score: 0.5535 - val_loss: 3.6799 - val_accuracy: 0.3093 - val_f1_score: 0.2563\n",
      "Epoch 418/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4928 - accuracy: 0.5693 - f1_score: 0.5556 - val_loss: 3.5607 - val_accuracy: 0.3285 - val_f1_score: 0.2691\n",
      "Epoch 419/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.5068 - accuracy: 0.5655 - f1_score: 0.5518 - val_loss: 3.6372 - val_accuracy: 0.3228 - val_f1_score: 0.2684\n",
      "Epoch 420/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4919 - accuracy: 0.5715 - f1_score: 0.5562 - val_loss: 3.6983 - val_accuracy: 0.3167 - val_f1_score: 0.2549\n",
      "Saved model and history at epoch 420\n",
      "Epoch 421/500\n",
      "386/386 [==============================] - 94s 244ms/step - loss: 1.4979 - accuracy: 0.5617 - f1_score: 0.5550 - val_loss: 3.6442 - val_accuracy: 0.3192 - val_f1_score: 0.2609\n",
      "Epoch 422/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.4855 - accuracy: 0.5727 - f1_score: 0.5602 - val_loss: 3.8465 - val_accuracy: 0.3121 - val_f1_score: 0.2545\n",
      "Epoch 423/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.5044 - accuracy: 0.5659 - f1_score: 0.5545 - val_loss: 3.8659 - val_accuracy: 0.3036 - val_f1_score: 0.2492\n",
      "Epoch 424/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4672 - accuracy: 0.5795 - f1_score: 0.5672 - val_loss: 3.6653 - val_accuracy: 0.3175 - val_f1_score: 0.2663\n",
      "Epoch 425/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4682 - accuracy: 0.5725 - f1_score: 0.5622 - val_loss: 3.6170 - val_accuracy: 0.3214 - val_f1_score: 0.2567\n",
      "Epoch 426/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4918 - accuracy: 0.5671 - f1_score: 0.5573 - val_loss: 3.7581 - val_accuracy: 0.3189 - val_f1_score: 0.2599\n",
      "Epoch 427/500\n",
      "386/386 [==============================] - 93s 242ms/step - loss: 1.4670 - accuracy: 0.5770 - f1_score: 0.5669 - val_loss: 3.6908 - val_accuracy: 0.3178 - val_f1_score: 0.2588\n",
      "Epoch 428/500\n",
      "386/386 [==============================] - 93s 242ms/step - loss: 1.4704 - accuracy: 0.5705 - f1_score: 0.5635 - val_loss: 3.7701 - val_accuracy: 0.3153 - val_f1_score: 0.2670\n",
      "Epoch 429/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4701 - accuracy: 0.5703 - f1_score: 0.5584 - val_loss: 3.8345 - val_accuracy: 0.3175 - val_f1_score: 0.2627\n",
      "Epoch 430/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4874 - accuracy: 0.5693 - f1_score: 0.5630 - val_loss: 3.7820 - val_accuracy: 0.3146 - val_f1_score: 0.2620\n",
      "Saved model and history at epoch 430\n",
      "Epoch 431/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4861 - accuracy: 0.5706 - f1_score: 0.5540 - val_loss: 3.6854 - val_accuracy: 0.3196 - val_f1_score: 0.2648\n",
      "Epoch 432/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4520 - accuracy: 0.5748 - f1_score: 0.5694 - val_loss: 3.7083 - val_accuracy: 0.3139 - val_f1_score: 0.2602\n",
      "Epoch 433/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.4824 - accuracy: 0.5727 - f1_score: 0.5631 - val_loss: 3.9218 - val_accuracy: 0.3157 - val_f1_score: 0.2720\n",
      "Epoch 434/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4661 - accuracy: 0.5765 - f1_score: 0.5686 - val_loss: 3.6819 - val_accuracy: 0.3274 - val_f1_score: 0.2698\n",
      "Epoch 435/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.4695 - accuracy: 0.5711 - f1_score: 0.5611 - val_loss: 4.0738 - val_accuracy: 0.3054 - val_f1_score: 0.2496\n",
      "Epoch 436/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.4591 - accuracy: 0.5766 - f1_score: 0.5669 - val_loss: 3.7718 - val_accuracy: 0.3235 - val_f1_score: 0.2624\n",
      "Epoch 437/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4362 - accuracy: 0.5799 - f1_score: 0.5716 - val_loss: 3.8703 - val_accuracy: 0.3125 - val_f1_score: 0.2567\n",
      "Epoch 438/500\n",
      "386/386 [==============================] - 94s 244ms/step - loss: 1.4593 - accuracy: 0.5738 - f1_score: 0.5659 - val_loss: 3.8359 - val_accuracy: 0.3167 - val_f1_score: 0.2663\n",
      "Epoch 439/500\n",
      "386/386 [==============================] - 93s 242ms/step - loss: 1.4469 - accuracy: 0.5790 - f1_score: 0.5686 - val_loss: 3.7209 - val_accuracy: 0.3278 - val_f1_score: 0.2727\n",
      "Epoch 440/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4375 - accuracy: 0.5804 - f1_score: 0.5728 - val_loss: 3.8574 - val_accuracy: 0.3103 - val_f1_score: 0.2602\n",
      "Saved model and history at epoch 440\n",
      "Epoch 441/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4568 - accuracy: 0.5810 - f1_score: 0.5704 - val_loss: 3.9676 - val_accuracy: 0.3132 - val_f1_score: 0.2581\n",
      "Epoch 442/500\n",
      "386/386 [==============================] - 92s 240ms/step - loss: 1.4551 - accuracy: 0.5803 - f1_score: 0.5717 - val_loss: 3.8009 - val_accuracy: 0.3203 - val_f1_score: 0.2645\n",
      "Epoch 443/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4377 - accuracy: 0.5810 - f1_score: 0.5729 - val_loss: 3.8562 - val_accuracy: 0.3157 - val_f1_score: 0.2666\n",
      "Epoch 444/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4328 - accuracy: 0.5835 - f1_score: 0.5739 - val_loss: 3.8361 - val_accuracy: 0.3153 - val_f1_score: 0.2602\n",
      "Epoch 445/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4510 - accuracy: 0.5726 - f1_score: 0.5662 - val_loss: 3.8016 - val_accuracy: 0.3228 - val_f1_score: 0.2702\n",
      "Epoch 446/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4423 - accuracy: 0.5791 - f1_score: 0.5742 - val_loss: 3.8052 - val_accuracy: 0.3178 - val_f1_score: 0.2641\n",
      "Epoch 447/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4680 - accuracy: 0.5731 - f1_score: 0.5634 - val_loss: 3.8747 - val_accuracy: 0.3153 - val_f1_score: 0.2631\n",
      "Epoch 448/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4337 - accuracy: 0.5781 - f1_score: 0.5699 - val_loss: 4.0454 - val_accuracy: 0.3107 - val_f1_score: 0.2609\n",
      "Epoch 449/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4295 - accuracy: 0.5842 - f1_score: 0.5754 - val_loss: 3.7713 - val_accuracy: 0.3185 - val_f1_score: 0.2663\n",
      "Epoch 450/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4414 - accuracy: 0.5822 - f1_score: 0.5706 - val_loss: 3.8728 - val_accuracy: 0.3224 - val_f1_score: 0.2712\n",
      "Saved model and history at epoch 450\n",
      "Epoch 451/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4368 - accuracy: 0.5856 - f1_score: 0.5734 - val_loss: 3.6830 - val_accuracy: 0.3267 - val_f1_score: 0.2744\n",
      "Epoch 452/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.4433 - accuracy: 0.5792 - f1_score: 0.5677 - val_loss: 3.8259 - val_accuracy: 0.3271 - val_f1_score: 0.2766\n",
      "Epoch 453/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4426 - accuracy: 0.5853 - f1_score: 0.5789 - val_loss: 3.6884 - val_accuracy: 0.3327 - val_f1_score: 0.2787\n",
      "Epoch 454/500\n",
      "386/386 [==============================] - 92s 240ms/step - loss: 1.4218 - accuracy: 0.5816 - f1_score: 0.5727 - val_loss: 3.8087 - val_accuracy: 0.3327 - val_f1_score: 0.2858\n",
      "Epoch 455/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4120 - accuracy: 0.5886 - f1_score: 0.5812 - val_loss: 3.7488 - val_accuracy: 0.3263 - val_f1_score: 0.2766\n",
      "Epoch 456/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4259 - accuracy: 0.5834 - f1_score: 0.5781 - val_loss: 3.8596 - val_accuracy: 0.3292 - val_f1_score: 0.2766\n",
      "Epoch 457/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4053 - accuracy: 0.5870 - f1_score: 0.5824 - val_loss: 3.7674 - val_accuracy: 0.3335 - val_f1_score: 0.2805\n",
      "Epoch 458/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.4257 - accuracy: 0.5846 - f1_score: 0.5777 - val_loss: 3.7612 - val_accuracy: 0.3306 - val_f1_score: 0.2844\n",
      "Epoch 459/500\n",
      "386/386 [==============================] - 92s 240ms/step - loss: 1.4361 - accuracy: 0.5853 - f1_score: 0.5791 - val_loss: 3.6685 - val_accuracy: 0.3345 - val_f1_score: 0.2791\n",
      "Epoch 460/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4148 - accuracy: 0.5889 - f1_score: 0.5833 - val_loss: 3.8447 - val_accuracy: 0.3278 - val_f1_score: 0.2769\n",
      "Saved model and history at epoch 460\n",
      "Epoch 461/500\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 1.4173 - accuracy: 0.5882 - f1_score: 0.5773 - val_loss: 3.7904 - val_accuracy: 0.3352 - val_f1_score: 0.2776\n",
      "Epoch 462/500\n",
      "386/386 [==============================] - 94s 243ms/step - loss: 1.4276 - accuracy: 0.5890 - f1_score: 0.5859 - val_loss: 3.8938 - val_accuracy: 0.3278 - val_f1_score: 0.2784\n",
      "Epoch 463/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.4067 - accuracy: 0.5899 - f1_score: 0.5804 - val_loss: 3.7681 - val_accuracy: 0.3292 - val_f1_score: 0.2762\n",
      "Epoch 464/500\n",
      "386/386 [==============================] - 94s 242ms/step - loss: 1.4126 - accuracy: 0.5879 - f1_score: 0.5826 - val_loss: 3.8820 - val_accuracy: 0.3295 - val_f1_score: 0.2762\n",
      "Epoch 465/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.4116 - accuracy: 0.5893 - f1_score: 0.5795 - val_loss: 4.0477 - val_accuracy: 0.3185 - val_f1_score: 0.2702\n",
      "Epoch 466/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.4025 - accuracy: 0.5930 - f1_score: 0.5880 - val_loss: 3.7047 - val_accuracy: 0.3391 - val_f1_score: 0.2933\n",
      "Epoch 467/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.4046 - accuracy: 0.5882 - f1_score: 0.5798 - val_loss: 3.9462 - val_accuracy: 0.3139 - val_f1_score: 0.2759\n",
      "Epoch 468/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.4040 - accuracy: 0.5910 - f1_score: 0.5836 - val_loss: 4.0150 - val_accuracy: 0.3235 - val_f1_score: 0.2702\n",
      "Epoch 469/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.3967 - accuracy: 0.5954 - f1_score: 0.5869 - val_loss: 3.8433 - val_accuracy: 0.3363 - val_f1_score: 0.2872\n",
      "Epoch 470/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4156 - accuracy: 0.5934 - f1_score: 0.5832 - val_loss: 3.7534 - val_accuracy: 0.3374 - val_f1_score: 0.2833\n",
      "Saved model and history at epoch 470\n",
      "Epoch 471/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.4096 - accuracy: 0.5922 - f1_score: 0.5837 - val_loss: 3.9144 - val_accuracy: 0.3224 - val_f1_score: 0.2780\n",
      "Epoch 472/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.3891 - accuracy: 0.5977 - f1_score: 0.5885 - val_loss: 3.9006 - val_accuracy: 0.3267 - val_f1_score: 0.2784\n",
      "Epoch 473/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.3748 - accuracy: 0.6002 - f1_score: 0.5928 - val_loss: 3.8302 - val_accuracy: 0.3399 - val_f1_score: 0.2887\n",
      "Epoch 474/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.3970 - accuracy: 0.5979 - f1_score: 0.5864 - val_loss: 3.8562 - val_accuracy: 0.3274 - val_f1_score: 0.2752\n",
      "Epoch 475/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.3812 - accuracy: 0.5986 - f1_score: 0.5880 - val_loss: 3.7774 - val_accuracy: 0.3299 - val_f1_score: 0.2776\n",
      "Epoch 476/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.4010 - accuracy: 0.5947 - f1_score: 0.5862 - val_loss: 3.9201 - val_accuracy: 0.3263 - val_f1_score: 0.2801\n",
      "Epoch 477/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.3970 - accuracy: 0.5926 - f1_score: 0.5836 - val_loss: 3.8278 - val_accuracy: 0.3274 - val_f1_score: 0.2773\n",
      "Epoch 478/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.3747 - accuracy: 0.5973 - f1_score: 0.5893 - val_loss: 4.0909 - val_accuracy: 0.3235 - val_f1_score: 0.2720\n",
      "Epoch 479/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.4065 - accuracy: 0.5922 - f1_score: 0.5885 - val_loss: 3.8336 - val_accuracy: 0.3313 - val_f1_score: 0.2812\n",
      "Epoch 480/500\n",
      "386/386 [==============================] - 92s 240ms/step - loss: 1.3768 - accuracy: 0.5999 - f1_score: 0.5902 - val_loss: 3.8842 - val_accuracy: 0.3303 - val_f1_score: 0.2826\n",
      "Saved model and history at epoch 480\n",
      "Epoch 481/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.3997 - accuracy: 0.5946 - f1_score: 0.5873 - val_loss: 3.8856 - val_accuracy: 0.3349 - val_f1_score: 0.2890\n",
      "Epoch 482/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.3692 - accuracy: 0.6013 - f1_score: 0.5949 - val_loss: 3.7558 - val_accuracy: 0.3367 - val_f1_score: 0.2855\n",
      "Epoch 483/500\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 1.3714 - accuracy: 0.5996 - f1_score: 0.5960 - val_loss: 3.9440 - val_accuracy: 0.3278 - val_f1_score: 0.2755\n",
      "Epoch 484/500\n",
      "386/386 [==============================] - 93s 241ms/step - loss: 1.3708 - accuracy: 0.5956 - f1_score: 0.5926 - val_loss: 3.8103 - val_accuracy: 0.3345 - val_f1_score: 0.2855\n",
      "Epoch 485/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.3596 - accuracy: 0.6036 - f1_score: 0.5995 - val_loss: 4.0204 - val_accuracy: 0.3242 - val_f1_score: 0.2730\n",
      "Epoch 486/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.3651 - accuracy: 0.5997 - f1_score: 0.5940 - val_loss: 3.8128 - val_accuracy: 0.3409 - val_f1_score: 0.2830\n",
      "Epoch 487/500\n",
      "386/386 [==============================] - 93s 240ms/step - loss: 1.3738 - accuracy: 0.5979 - f1_score: 0.5933 - val_loss: 3.9722 - val_accuracy: 0.3320 - val_f1_score: 0.2826\n",
      "Epoch 488/500\n",
      "386/386 [==============================] - 100s 258ms/step - loss: 1.3634 - accuracy: 0.6017 - f1_score: 0.5970 - val_loss: 3.8531 - val_accuracy: 0.3370 - val_f1_score: 0.2858\n",
      "Epoch 489/500\n",
      "386/386 [==============================] - 100s 259ms/step - loss: 1.3773 - accuracy: 0.6060 - f1_score: 0.5956 - val_loss: 3.7570 - val_accuracy: 0.3402 - val_f1_score: 0.2851\n",
      "Epoch 490/500\n",
      "386/386 [==============================] - 91s 237ms/step - loss: 1.3565 - accuracy: 0.6035 - f1_score: 0.5945 - val_loss: 3.9369 - val_accuracy: 0.3327 - val_f1_score: 0.2791\n",
      "Saved model and history at epoch 490\n",
      "Epoch 491/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.3544 - accuracy: 0.6054 - f1_score: 0.6010 - val_loss: 3.9248 - val_accuracy: 0.3374 - val_f1_score: 0.2887\n",
      "Epoch 492/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.3515 - accuracy: 0.6053 - f1_score: 0.6026 - val_loss: 4.0005 - val_accuracy: 0.3271 - val_f1_score: 0.2815\n",
      "Epoch 493/500\n",
      "386/386 [==============================] - 90s 234ms/step - loss: 1.3841 - accuracy: 0.5974 - f1_score: 0.5945 - val_loss: 3.7903 - val_accuracy: 0.3391 - val_f1_score: 0.2833\n",
      "Epoch 494/500\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.3650 - accuracy: 0.6013 - f1_score: 0.5957 - val_loss: 3.9764 - val_accuracy: 0.3310 - val_f1_score: 0.2798\n",
      "Epoch 495/500\n",
      "386/386 [==============================] - 90s 233ms/step - loss: 1.3631 - accuracy: 0.5993 - f1_score: 0.5977 - val_loss: 3.8210 - val_accuracy: 0.3363 - val_f1_score: 0.2826\n",
      "Epoch 496/500\n",
      "386/386 [==============================] - 91s 235ms/step - loss: 1.3835 - accuracy: 0.6008 - f1_score: 0.5956 - val_loss: 3.8686 - val_accuracy: 0.3292 - val_f1_score: 0.2741\n",
      "Epoch 497/500\n",
      "386/386 [==============================] - 107s 278ms/step - loss: 1.3616 - accuracy: 0.6003 - f1_score: 0.5958 - val_loss: 3.9724 - val_accuracy: 0.3356 - val_f1_score: 0.2883\n",
      "Epoch 498/500\n",
      "386/386 [==============================] - 114s 295ms/step - loss: 1.3728 - accuracy: 0.6011 - f1_score: 0.5974 - val_loss: 3.9501 - val_accuracy: 0.3271 - val_f1_score: 0.2766\n",
      "Epoch 499/500\n",
      "386/386 [==============================] - 113s 292ms/step - loss: 1.3585 - accuracy: 0.6041 - f1_score: 0.5976 - val_loss: 3.9735 - val_accuracy: 0.3327 - val_f1_score: 0.2773\n",
      "Epoch 500/500\n",
      "386/386 [==============================] - 113s 291ms/step - loss: 1.3529 - accuracy: 0.6014 - f1_score: 0.5974 - val_loss: 3.8606 - val_accuracy: 0.3235 - val_f1_score: 0.2787\n",
      "Saved model and history at epoch 500\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save it\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    train_and_save(\n",
    "        model, \n",
    "        training_generator, \n",
    "        validation_generator, \n",
    "        epochs=260, \n",
    "        save_interval=10, \n",
    "        model_save_path=\"models\", \n",
    "        history_save_path=\"history.csv\", \n",
    "        custom_metrics=[f1_score],\n",
    "        custom_optimizer=opt\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

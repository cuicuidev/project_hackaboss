{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "GPU 1: PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for i, device in enumerate(physical_devices):\n",
    "    print(f\"GPU {i}: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'car_make_images/'\n",
    "training_path = path + 'train'\n",
    "testing_path = path + 'test'\n",
    "validation_path = path + 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_generator = ImageDataGenerator(rescale = 1./255,\n",
    "                              rotation_range = 359,\n",
    "                              shear_range = 0.2,\n",
    "                              width_shift_range = 0.2,\n",
    "                              height_shift_range = 0.2,\n",
    "                              zoom_range = 0.2,\n",
    "                              horizontal_flip = True,\n",
    "                              vertical_flip = True,\n",
    "                              preprocessing_function = None)\n",
    "\n",
    "validation_data_generator = ImageDataGenerator(rescale = 1./255)\n",
    "test_data_generator = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11573 images belonging to 39 classes.\n",
      "Found 2813 images belonging to 39 classes.\n",
      "Found 2871 images belonging to 39 classes.\n"
     ]
    }
   ],
   "source": [
    "size = 200\n",
    "batch_size = 30  \n",
    "num_classes = 39\n",
    "\n",
    "training_generator = training_data_generator.flow_from_directory(training_path,\n",
    "                                                                 target_size = (size, size),\n",
    "                                                                 batch_size = 30,\n",
    "                                                                 class_mode = \"categorical\",\n",
    "                                                                 color_mode = 'grayscale',\n",
    "                                                                 )\n",
    "\n",
    "validation_generator = validation_data_generator.flow_from_directory(validation_path,\n",
    "                                                                     target_size = (size, size),\n",
    "                                                                     batch_size = 1,\n",
    "                                                                     class_mode = \"categorical\",\n",
    "                                                                     color_mode = 'grayscale',\n",
    "                                                                     )\n",
    "\n",
    "test_generator = test_data_generator.flow_from_directory(testing_path,\n",
    "                                                         target_size = (size, size),\n",
    "                                                         batch_size = 1,\n",
    "                                                         class_mode = \"categorical\",\n",
    "                                                         color_mode = 'grayscale',\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/GPU:0\"):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(size, size, 1)))\n",
    "\n",
    "    # First Conv Block\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal'))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Second Conv Block\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal'))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Third Conv Block\n",
    "    model.add(Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal'))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Fourth Conv Block\n",
    "    model.add(Conv2D(filters=256, kernel_size=3, padding='same', kernel_initializer='he_normal'))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Flatten and Fully Connected Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_initializer='he_normal'))\n",
    "\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate=0.001,\n",
    "                decay_steps=10000,\n",
    "                decay_rate=0.9)\n",
    "    opt = Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(model, train_data, val_data, epochs, save_interval, model_save_path, history_save_path, custom_metrics=None, custom_optimizer=None):\n",
    "    \"\"\"\n",
    "    Train a TensorFlow model and save it along with its history.\n",
    "    \"\"\"\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "    if custom_optimizer:\n",
    "        optimizer = custom_optimizer\n",
    "    else:\n",
    "        optimizer = 'adam'\n",
    "\n",
    "    if custom_metrics:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'] + custom_metrics)\n",
    "    else:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    # Initialize variables\n",
    "    initial_epoch = 0\n",
    "    temp_history_data = []\n",
    "\n",
    "    # Check if history file exists, if not create it\n",
    "    if not os.path.exists(history_save_path):\n",
    "        with open(history_save_path, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            columns = ['Epoch', 'Loss', 'Accuracy', 'Val_Loss', 'Val_Accuracy']\n",
    "            if custom_metrics:\n",
    "                for metric in custom_metrics:\n",
    "                    metric_name = metric.__name__\n",
    "                    columns.append(metric_name)\n",
    "                    columns.append(\"Val_\" + metric_name)\n",
    "            csv_writer.writerow(columns)\n",
    "    else:\n",
    "        with open(history_save_path, 'r') as csvfile:\n",
    "            csv_reader = csv.reader(csvfile)\n",
    "            last_row = None\n",
    "            for row in csv_reader:\n",
    "                last_row = row\n",
    "            if last_row:\n",
    "                initial_epoch = int(last_row[0])\n",
    "\n",
    "    latest_model_file = max(glob.glob(f\"{model_save_path}/model_e*.h5\"), default=None, key=os.path.getctime)\n",
    "    if latest_model_file is not None:\n",
    "        print(f\"Resuming from {latest_model_file}\")\n",
    "        model = tf.keras.models.load_model(latest_model_file, custom_objects={metric.__name__: metric for metric in custom_metrics})\n",
    "\n",
    "    for epoch in range(initial_epoch + 1, epochs + initial_epoch + 1):\n",
    "        print(f\"Epoch {epoch}/{epochs + initial_epoch}\")\n",
    "\n",
    "        history = model.fit(train_data, validation_data=val_data)\n",
    "        history_data = [epoch] + [history.history[key][0] for key in history.history]\n",
    "        temp_history_data.append(history_data)\n",
    "\n",
    "        if epoch % save_interval == 0 or epoch == epochs + initial_epoch:\n",
    "            model_file_path = os.path.join(model_save_path, f\"model_e{epoch}.h5\")\n",
    "            model.save(model_file_path)\n",
    "\n",
    "            # Append to CSV at checkpoints\n",
    "            with open(history_save_path, 'a', newline='') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                for row in temp_history_data:\n",
    "                    csv_writer.writerow(row)\n",
    "\n",
    "            # Clear temporary history data\n",
    "            temp_history_data.clear()\n",
    "\n",
    "            print(f\"Saved model and history at epoch {epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    actual_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    \n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (actual_positives + K.epsilon())\n",
    "    \n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    return f1_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from models\\model_e200.h5\n",
      "Epoch 201/240\n",
      "386/386 [==============================] - 89s 230ms/step - loss: 2.1695 - accuracy: 0.3930 - f1_score: 0.3481 - val_loss: 3.3219 - val_accuracy: 0.2606 - val_f1_score: 0.1674\n",
      "Epoch 202/240\n",
      "386/386 [==============================] - 90s 233ms/step - loss: 2.1732 - accuracy: 0.3926 - f1_score: 0.3383 - val_loss: 3.1785 - val_accuracy: 0.2755 - val_f1_score: 0.1802\n",
      "Epoch 203/240\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 2.1516 - accuracy: 0.3971 - f1_score: 0.3501 - val_loss: 3.2532 - val_accuracy: 0.2659 - val_f1_score: 0.1724\n",
      "Epoch 204/240\n",
      "386/386 [==============================] - 106s 274ms/step - loss: 2.1419 - accuracy: 0.3989 - f1_score: 0.3492 - val_loss: 3.2700 - val_accuracy: 0.2627 - val_f1_score: 0.1770\n",
      "Epoch 205/240\n",
      "386/386 [==============================] - 104s 270ms/step - loss: 2.1526 - accuracy: 0.3966 - f1_score: 0.3442 - val_loss: 3.2990 - val_accuracy: 0.2695 - val_f1_score: 0.1809\n",
      "Epoch 206/240\n",
      "386/386 [==============================] - 105s 272ms/step - loss: 2.1260 - accuracy: 0.4007 - f1_score: 0.3557 - val_loss: 3.1684 - val_accuracy: 0.2815 - val_f1_score: 0.1905\n",
      "Epoch 207/240\n",
      "386/386 [==============================] - 105s 270ms/step - loss: 2.1259 - accuracy: 0.4051 - f1_score: 0.3604 - val_loss: 3.3180 - val_accuracy: 0.2659 - val_f1_score: 0.1856\n",
      "Epoch 208/240\n",
      "386/386 [==============================] - 105s 272ms/step - loss: 2.1255 - accuracy: 0.4034 - f1_score: 0.3570 - val_loss: 3.2646 - val_accuracy: 0.2663 - val_f1_score: 0.1802\n",
      "Epoch 209/240\n",
      "386/386 [==============================] - 137s 355ms/step - loss: 2.1174 - accuracy: 0.4037 - f1_score: 0.3559 - val_loss: 3.2160 - val_accuracy: 0.2801 - val_f1_score: 0.1905\n",
      "Epoch 210/240\n",
      "386/386 [==============================] - 113s 293ms/step - loss: 2.1002 - accuracy: 0.4149 - f1_score: 0.3625 - val_loss: 3.1963 - val_accuracy: 0.2723 - val_f1_score: 0.1806\n",
      "Saved model and history at epoch 210\n",
      "Epoch 211/240\n",
      "386/386 [==============================] - 149s 386ms/step - loss: 2.1244 - accuracy: 0.4059 - f1_score: 0.3621 - val_loss: 3.2136 - val_accuracy: 0.2798 - val_f1_score: 0.1884\n",
      "Epoch 212/240\n",
      "386/386 [==============================] - 110s 284ms/step - loss: 2.1080 - accuracy: 0.4110 - f1_score: 0.3601 - val_loss: 3.1861 - val_accuracy: 0.2737 - val_f1_score: 0.1849\n",
      "Epoch 213/240\n",
      "386/386 [==============================] - 126s 327ms/step - loss: 2.0806 - accuracy: 0.4182 - f1_score: 0.3727 - val_loss: 3.3585 - val_accuracy: 0.2712 - val_f1_score: 0.1873\n",
      "Epoch 214/240\n",
      "386/386 [==============================] - 103s 266ms/step - loss: 2.0892 - accuracy: 0.4123 - f1_score: 0.3711 - val_loss: 3.1992 - val_accuracy: 0.2833 - val_f1_score: 0.1991\n",
      "Epoch 215/240\n",
      "386/386 [==============================] - 90s 234ms/step - loss: 2.0968 - accuracy: 0.4131 - f1_score: 0.3656 - val_loss: 3.4470 - val_accuracy: 0.2588 - val_f1_score: 0.1767\n",
      "Epoch 216/240\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 2.0920 - accuracy: 0.4135 - f1_score: 0.3671 - val_loss: 3.4158 - val_accuracy: 0.2656 - val_f1_score: 0.1820\n",
      "Epoch 217/240\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 2.0741 - accuracy: 0.4167 - f1_score: 0.3710 - val_loss: 3.3497 - val_accuracy: 0.2677 - val_f1_score: 0.1866\n",
      "Epoch 218/240\n",
      "386/386 [==============================] - 91s 237ms/step - loss: 2.0719 - accuracy: 0.4167 - f1_score: 0.3748 - val_loss: 3.3535 - val_accuracy: 0.2584 - val_f1_score: 0.1795\n",
      "Epoch 219/240\n",
      "386/386 [==============================] - 90s 234ms/step - loss: 2.0742 - accuracy: 0.4117 - f1_score: 0.3753 - val_loss: 3.3032 - val_accuracy: 0.2709 - val_f1_score: 0.1891\n",
      "Epoch 220/240\n",
      "386/386 [==============================] - 89s 232ms/step - loss: 2.0671 - accuracy: 0.4180 - f1_score: 0.3798 - val_loss: 3.2372 - val_accuracy: 0.2784 - val_f1_score: 0.1916\n",
      "Saved model and history at epoch 220\n",
      "Epoch 221/240\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 2.0619 - accuracy: 0.4171 - f1_score: 0.3787 - val_loss: 3.2971 - val_accuracy: 0.2734 - val_f1_score: 0.1888\n",
      "Epoch 222/240\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 2.0548 - accuracy: 0.4196 - f1_score: 0.3842 - val_loss: 3.3752 - val_accuracy: 0.2670 - val_f1_score: 0.1888\n",
      "Epoch 223/240\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 2.0432 - accuracy: 0.4200 - f1_score: 0.3823 - val_loss: 3.3949 - val_accuracy: 0.2677 - val_f1_score: 0.1849\n",
      "Epoch 224/240\n",
      "386/386 [==============================] - 92s 240ms/step - loss: 2.0574 - accuracy: 0.4193 - f1_score: 0.3830 - val_loss: 3.3348 - val_accuracy: 0.2670 - val_f1_score: 0.1948\n",
      "Epoch 225/240\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 2.0632 - accuracy: 0.4147 - f1_score: 0.3838 - val_loss: 3.4745 - val_accuracy: 0.2734 - val_f1_score: 0.1902\n",
      "Epoch 226/240\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 2.0292 - accuracy: 0.4282 - f1_score: 0.3862 - val_loss: 3.2589 - val_accuracy: 0.2908 - val_f1_score: 0.2112\n",
      "Epoch 227/240\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 2.0455 - accuracy: 0.4229 - f1_score: 0.3809 - val_loss: 3.3017 - val_accuracy: 0.2723 - val_f1_score: 0.2005\n",
      "Epoch 228/240\n",
      "386/386 [==============================] - 92s 237ms/step - loss: 2.0406 - accuracy: 0.4200 - f1_score: 0.3818 - val_loss: 3.2311 - val_accuracy: 0.2872 - val_f1_score: 0.1945\n",
      "Epoch 229/240\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 2.0312 - accuracy: 0.4298 - f1_score: 0.3882 - val_loss: 3.3455 - val_accuracy: 0.2773 - val_f1_score: 0.1973\n",
      "Epoch 230/240\n",
      "386/386 [==============================] - 90s 233ms/step - loss: 2.0464 - accuracy: 0.4262 - f1_score: 0.3829 - val_loss: 3.3996 - val_accuracy: 0.2634 - val_f1_score: 0.1852\n",
      "Saved model and history at epoch 230\n",
      "Epoch 231/240\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 2.0372 - accuracy: 0.4282 - f1_score: 0.3826 - val_loss: 3.3606 - val_accuracy: 0.2734 - val_f1_score: 0.1948\n",
      "Epoch 232/240\n",
      "386/386 [==============================] - 91s 237ms/step - loss: 2.0167 - accuracy: 0.4335 - f1_score: 0.3856 - val_loss: 3.3707 - val_accuracy: 0.2748 - val_f1_score: 0.1959\n",
      "Epoch 233/240\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 2.0119 - accuracy: 0.4237 - f1_score: 0.3906 - val_loss: 3.3669 - val_accuracy: 0.2830 - val_f1_score: 0.2030\n",
      "Epoch 234/240\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 2.0366 - accuracy: 0.4260 - f1_score: 0.3831 - val_loss: 3.1931 - val_accuracy: 0.2936 - val_f1_score: 0.2044\n",
      "Epoch 235/240\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 2.0084 - accuracy: 0.4294 - f1_score: 0.3894 - val_loss: 3.3194 - val_accuracy: 0.2776 - val_f1_score: 0.2016\n",
      "Epoch 236/240\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 1.9984 - accuracy: 0.4331 - f1_score: 0.3944 - val_loss: 3.4867 - val_accuracy: 0.2773 - val_f1_score: 0.2026\n",
      "Epoch 237/240\n",
      "386/386 [==============================] - 92s 239ms/step - loss: 2.0075 - accuracy: 0.4376 - f1_score: 0.3976 - val_loss: 3.4196 - val_accuracy: 0.2833 - val_f1_score: 0.1991\n",
      "Epoch 238/240\n",
      "386/386 [==============================] - 92s 238ms/step - loss: 2.0058 - accuracy: 0.4354 - f1_score: 0.4007 - val_loss: 3.3620 - val_accuracy: 0.2727 - val_f1_score: 0.1977\n",
      "Epoch 239/240\n",
      "386/386 [==============================] - 91s 236ms/step - loss: 2.0021 - accuracy: 0.4323 - f1_score: 0.3972 - val_loss: 3.3875 - val_accuracy: 0.2819 - val_f1_score: 0.2069\n",
      "Epoch 240/240\n",
      "386/386 [==============================] - 90s 234ms/step - loss: 1.9808 - accuracy: 0.4415 - f1_score: 0.4046 - val_loss: 3.2884 - val_accuracy: 0.2844 - val_f1_score: 0.2065\n",
      "Saved model and history at epoch 240\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save it\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    train_and_save(\n",
    "        model, \n",
    "        training_generator, \n",
    "        validation_generator, \n",
    "        epochs=40, \n",
    "        save_interval=10, \n",
    "        model_save_path=\"models\", \n",
    "        history_save_path=\"history.csv\", \n",
    "        custom_metrics=[f1_score],\n",
    "        custom_optimizer=opt\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
